{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN2110 obligatorisk innlevering 1b\n",
    "\n",
    "Oppgaven har to deler, logistisk regresjon for å klassifisere språk basert på IPA lydskrift, og Named Entity Recognition med HMM. Det er en god idé å lese gjennom hele oppgavesettet før du setter i gang. \n",
    "\n",
    "Dersom du har spørsmål så kan du:\n",
    "\n",
    "* gå på gruppetime,\n",
    "* spørre på Discourse\n",
    "* eller sende epost til in2110-hjelp@ifi.uio.no dersom alternativene over av en eller annen grunn ikke passer for spørsmålet ditt.\n",
    "\n",
    "### Oppsett\n",
    "Når du har klonet dette github-repoet som denne notebooken ligger i, har du tilgang til datene og hjelpefilene som ligger i denne mappa. Hvis du ønsker å kopiere denne mappa, \"1b\", over til et annet sted, så skulle det gå bra. Bare pass på at du følger med på om det er oppdateringer her i repoet som gir ut obligen. Når du har aktivert in2110-miljøet med conda, så har du tilgang til pakkene som trengs for å kjøre denne notebooken. Vi har forberedt en notebook med all prekoden, der du også kan fylle ut din kode og kjøre prosessene.\n",
    "\n",
    "### Innlevering\n",
    "\n",
    "Innleveringen skal helst bestå av denne Jupyter notebook fylt ut med både kode og tilhørende forklaringer. Vi understreker at innlevering av koden alene __ikke er nok__ for å bestå oppgaven -- vi forventer at notebooken også skal inneholde _beskrivelser_ (på norsk eller engelsk) av hva dere har gjort og _begrunnelser_ for valgene dere har tatt underveis. Bruk helst hele setninger, og matematiske formler om nødvendig. Evalueringstallene bør presenteres i tabeller. Det å  forklare med egne ord (samt begreper vi har gått gjennom på forelesningene) hva dere har implementert og reflektere over hvorvidt løsningen dere har lagt  besvarer oppgaven er en viktig del av læringsprosessen -- ta det på alvor! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 1: Logistisk regresjon\n",
    "\n",
    "\n",
    "I den første delen av innleveringen skal vi bruke logistisk regresjon til å utvikle en enkel _språkidentifikator_, dvs. et lite system som skal predikere hvilket språk et ord hører til. Mer spesifikk skal systemet ta ordets _fonetiske transkripsjon_ som input og returnere _navnet på språket_ som ordet mest sannsynlig tilhører.  Systemet skal for eksempel kunne ta transkripsjonen [bʊndɛsvɛɾfaszʊŋ] som input og returnere ``tysk''. \n",
    "\n",
    "## Data\n",
    "\n",
    "For å trene modellen (dvs. finne ut verdier for vektene og skjæringspunktene basert på data) skal vi ta i bruk eksisterende lister over ord med deres fonetiske transkripsjon i såkalt _IPA_-format (IPA står for _[International Phonetic Alphabet](https://upload.wikimedia.org/wikipedia/commons/8/8e/IPA_chart_2018.pdf)_).  Dere trenger ikke å kunne lese eller skrive slike fonetiske transkripsjoner i denne oppgaven. Det viktigste er å forstå at disse transkripsjonene beskriver språklydene som utgjør ordet, samt andre egenskaper slik som lengde, tone, trykk og intonasjon. Fonetiske transkripsjoner forteller oss hvordan et ord bør uttales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached file from ./langid_data.csv\n",
      "Treningsett: 689238 eksempler, testsett: 76583 eksempler\n"
     ]
    }
   ],
   "source": [
    "import oblig1b_utils \n",
    "train_data, test_data = oblig1b_utils.extract_wordlist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data vi skal bruke er lagt i to `DataFrame` tabeller: et treningsett med 90 % av ordene og et testsett med de resterende 10 %. Ordene fra de forskjellige språkene er blandet i disse to tabellene. `DataFrame` er en datastruktur fra Python-biblioteket [`pandas`](https://pandas.pydata.org) og representerer en slags tabell med kolonner og rader. Biblioteket `pandas` gjør det lett å visualisere og manipulere slike tabeller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistikk over språkene i treningsett:\n",
      "språk\n",
      "islandsk        45146\n",
      "fransk          45093\n",
      "engelsk         45068\n",
      "tysk            45044\n",
      "spansk          45043\n",
      "finsk           45017\n",
      "arabisk         45017\n",
      "koreansk        44926\n",
      "rumensk         44893\n",
      "japansk         44886\n",
      "kantonesisk     44879\n",
      "vietnamesisk    44829\n",
      "swahilisk       43511\n",
      "mandarin        40375\n",
      "malayisk        25463\n",
      "svensk          19046\n",
      "norsk            9127\n",
      "farsi            7246\n",
      "khmer            2959\n",
      "patwa            1670\n",
      "Name: count, dtype: int64\n",
      "Første 30 ord:\n",
      "                     ord                   IPA         språk\n",
      "552359             getah                 gətah      malayisk\n",
      "99407      enciclopedism        entʃiklopedism       rumensk\n",
      "102473        nhất thiết        ɲɤ̆k˦˥ tʰiək˦˥  vietnamesisk\n",
      "58664         poikakirja          ˈpoikɑˌkirjɑ         finsk\n",
      "329709        canalisons             kanalizɔ̃        fransk\n",
      "73430                tửu                tɯw˧˩˨  vietnamesisk\n",
      "12794   descontagiásemos     deskontaˈxjasemos        spansk\n",
      "349911               nưa                 nɯə˧˥  vietnamesisk\n",
      "400577                考古         kʰɑʊ˨˩˦ ku˨˩˦      mandarin\n",
      "279475          riðusmit             rɪːðʏsmɪt      islandsk\n",
      "311058            바시락거리다  pa̠ɕʰiɾa̠k̚k͈ʌ̹ɾida̠      koreansk\n",
      "221937                 衪                  i˨˩˦      mandarin\n",
      "247036          mabeseni              maɓeseni     swahilisk\n",
      "642032       aspirándola          aspiˈɾandola        spansk\n",
      "515783             trike               tɹˈa‍ɪk       engelsk\n",
      "58465      benediziertet     benədiˈt͡siːɐ̯tət          tysk\n",
      "533724   inflamabilitate       inflamabilitate       rumensk\n",
      "110678         sublimara             suβlimaɾa        spansk\n",
      "191336         eðlilegri             ɛðlɪlɛɣrɪ      islandsk\n",
      "655541    zusammenpacket      t͡suˈzamənˌpakət          tysk\n",
      "603996           viwavyo               viwavjo     swahilisk\n",
      "46248          angefuata             aᵑgefuata     swahilisk\n",
      "510925       kaflaskilum         kʰaplascɪːlʏm      islandsk\n",
      "197207          فبالسليح         fabiaːlsaliːħ       arabisk\n",
      "633038              jain                 dʒaɪn         patwa\n",
      "570713             annal                  anal        fransk\n",
      "72056            algezie             aldʒezije       rumensk\n",
      "278845                自慢                dʑimaɴ       japansk\n",
      "80661                  鿃                si:m˧˥   kantonesisk\n",
      "176788     desséchassent               deseʃas        fransk\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistikk over språkene i treningsett:\")\n",
    "print(train_data.språk.value_counts())\n",
    "print(\"Første 30 ord:\")\n",
    "print(train_data[:30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassen\n",
    "\n",
    "Her er skjelettet for `LanguageIdentifier`-klassen  som skal implementeres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "class LanguageIdentifier:\n",
    "    \"\"\"Logistisk regresjonsmodell som tar IPA transkripsjoner av ord som input, \n",
    "    og predikerer hvilke språkene disse ordene hører til.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialiser modellen\"\"\"      \n",
    "        # selve regresjonsmodellen (som brukes all CPU-er på maskinen for trening)\n",
    "        self.model = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", multi_class='ovr')\n",
    "    \n",
    "    def train(self, transcriptions, languages):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "        den logistisk regresjonsmodellen. De to rekkene må ha samme lendgen\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "        for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "        \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "        symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _extract_feats(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "        hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def evaluate(self, transcriptions, languages):  \n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "        modellen fungerer ved å beregne:\n",
    "        1) accuracy\n",
    "        2) precision, recall og F1 for hvert språk\n",
    "        3) micro- og macro-averaged F1.\n",
    "        \"\"\"\n",
    "        \n",
    "        # See API fra sklearn.metrics for å finne ut hvordan dette kan gjøres! \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening \n",
    "Vi skal benytte oss av en logistisk regresjonsmodell, mer spesifikk klassen [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) fra `scikit-learn`. Men for å kunne bruke modellen må vi naturligvis først estimere parametrene basert på treningsdata. \n",
    " Hva slags trekk (_features_) skal vi bruke i modellen vår? I denne oppgaven skal vi gjøre det enkelt for oss selv, og kun ta i betrakning forekomst av bestemte IPA-symboler som identifiserer ordlyder i den fonetiske transkripsjonen av ordet. _NB_: hvis du kan litt fonetikk fra før vil dere kanskje stusse på denne overforenklingen, da IPA-symboler brukes til å kode en god del andre egenskaper knyttet til talelyder slik som lengde, tone, trykk og intonasjon. Men i denne oppgaven skal vi gå den enkle veien og bruke alle symbolene i disse transkripsjonene uten å skille mellom ulike typer.\n",
    "\n",
    "Trekkene vil ha binære verdier (1 hvis transkripsjonen inneholder symbolet og 0 ellers) og kan sees som en slags ``bag-of-sounds'', siden de vil fortelle oss hvilke ordlyder som forekommer i ordet, men ikke i hvilken rekkefølge.\n",
    "\n",
    "__Opgave 1.1:__ Det første skrittet er å lage en liste over alle IPA-symboler som finnes i treningsettet. Metoden `_extract_unique_symbols` skal ta de fonetiske transkripsjonene fra treningssettet som input, og returnere en liste med alle fonetiske symboler (altså tegn) som finnes i disse transkripsjonene og forekommer minst 10 ganger. Implementer denne metoden. Antall symboler kan variere litt avhengig av den tilfeldige inndelingen mellom treningsettet og testsettet, men bør ligge på rundt 155 unike symboler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "    \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "    symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "    \n",
    "    symbols = {}\n",
    "    for word in transcriptions:\n",
    "        for symbol in word:\n",
    "            if symbol not in symbols:\n",
    "                symbols[symbol] = 0\n",
    "            symbols[symbol] += 1\n",
    "    \n",
    "    result = [symbol for symbol, n in symbols.items() if n > min_nb_occurrences]\n",
    "    return result\n",
    "    \n",
    "# her kobler vi metoden vi har implementert til klassen\n",
    "LanguageIdentifier._extract_unique_symbols = _extract_unique_symbols \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Oppgave 1.2__: Deretter må vi implementere metoden `_extract_feats` som tar en liste fonetiske transkripsjoner og returnerer en matrise $X$ hvor hver rad tilsvarer en transkripsjon og hver kolonne representerer et bestemt trekk. La oss si vi har $m$ unike fonetiske symboler (ekstrahert med metoden ovenfor), og får en liste med $n$ fonetiske transkripsjoner $T = \\{t_i \\text{ hvor } 0 < i < n\\}$. Metoden `_extract_feats(transcriptions)` må returnere en matrise $X$ av dimensjon $(n,m)$, hvor hver matrisecelle $X_{ij}$ er definert slik: \n",
    "\n",
    "$$\n",
    "X_{ij}  =  \\begin{cases} 1 \\text{  hvis symbolet } j \\text{ forekommer i transkripsjonen } t_i \\\\\n",
    "0 \\text{  ellers} \\end{cases} \n",
    "$$\n",
    "\n",
    "Tips: den enkleste fremgangsmåten kan være å starte med å lage en tom matrise slik som `X = np.zeros(n,m)` og deretter endre cellene hvor `X[i,j]` skal ha 1 som verdi i stedet for 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _extract_feats(self, transcriptions, unique_symbols):\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "    hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\"\"\"\n",
    "    \n",
    "    m = len(unique_symbols)\n",
    "    n = len(transcriptions)\n",
    "    \n",
    "    X = np.zeros((n, m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if unique_symbols[j] not in transcriptions[i]:\n",
    "                continue\n",
    "            X[i][j] = 1\n",
    "    \n",
    "    return X\n",
    "\n",
    "LanguageIdentifier._extract_feats = _extract_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oppgave 1.3__: Vi er nå klare til for å implementere funksjonen `train`. Metoden tar to lister som input, en liste fonetiske transkripsjoner og en liste med språknavn (de to listene må ha samme lengde). Metoden skal trene den logistiske regresjonsmodellen `self.model` ved å kalle `fit(X, y)`, hvor `X` er en matrise med alle trekk ekstrahert med metoden `_extract_feats`, og `y` er outputklassene. \n",
    "\n",
    "Merk at `scikit-learn` krever at outputklassene `y` må være en liste med heltall (og ikke strenger). Det betyr at dere må lage en mapping mellom språknavn og heltall (f.eks. ved å si at \"norsk\" er 0, \"arabisk\" er 1, \"finsk\" er 2, osv.). Når dere har både matrisen `X` og output `y` er det bare å kalle metoden `fit(X, y)` for å trene modellen. Trening kan ta noen minutter avhengig av maskinen deres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_languages(languages: list) -> list:\n",
    "    \"\"\"Gitt en rekke med språk, returnerer en rekke med unike språk\"\"\"\n",
    "    \n",
    "    unique_langs = []\n",
    "    for l in languages:\n",
    "        if l not in unique_langs:\n",
    "            unique_langs.append(l)\n",
    "    \n",
    "    return unique_langs\n",
    "\n",
    "def map_languages(languages: list, mapped: list =[]) -> list:\n",
    "    \"\"\"Metode som tar inn en rekke med språk og mapper de til hvert sitt heltall. \n",
    "    Man kan også decode hvilket språk en liste heltall er ved å sende inn språklisten og listen med tall som parametre\"\"\"\n",
    "    \n",
    "    y = [x for x in languages]\n",
    "    unique_langs = unique_languages(languages)\n",
    "    \n",
    "    for i, l in enumerate(y):\n",
    "        y[i] = unique_langs.index(l)\n",
    "    \n",
    "    if len(mapped) < 1:\n",
    "        return y\n",
    "    \n",
    "    if len(mapped) == 1:\n",
    "        mapped = mapped[0]\n",
    "        return unique_langs.index(mapped)\n",
    "    \n",
    "    return [unique_langs[x] for x in mapped]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self: LanguageIdentifier, transcriptions: list, languages: list) -> None:\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "    den logistisk regresjonsmodellen. De to rekkene må ha samme lengde.\"\"\"\n",
    "    \n",
    "    X = _extract_feats(self, transcriptions, _extract_unique_symbols(self, transcriptions))\n",
    "    y = map_languages(languages)\n",
    "    \n",
    "    self.model.fit(X, y)\n",
    "\n",
    "LanguageIdentifier.train = train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi er nå klare til å trene modellen (kan ta noen minutter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageIdentifier()\n",
    "transcriptions = train_data.IPA.values\n",
    "languages = train_data.språk.values\n",
    "model.train(transcriptions, languages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prediksjon og evaluering\n",
    "\n",
    "Når modellen er trent kan vi anvende den på nye fonetiske transkripsjoner. \n",
    "\n",
    "__Oppgave 1.4__: Implementer metoden `predict`. Metoden tar som input en liste fonetiske transkripsjoner og predikerer det mest sannsynlige språket for hver transkripsjon. Listen som returneres må ha samme lengde som inputlisten. Husk at `scikit-learn` opererer med outputklasser representert som heltall, så dere må forvandle disse tallene tilbake til språknavnene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self: LanguageIdentifier, test_transcriptions: list) -> list:\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "    for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "    \n",
    "    all_symbols = _extract_unique_symbols(self, transcriptions)\n",
    "    feats = _extract_feats(self, test_transcriptions, all_symbols)\n",
    "    preds = self.model.predict(feats)\n",
    "    preds = map_languages(languages, preds)\n",
    "    return preds\n",
    "\n",
    "LanguageIdentifier.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deretter kan dere se hvordan modellen fungerer i praksis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mest sansynnlige språk for ordene: ['spansk', 'norsk', 'islandsk', 'finsk']\n"
     ]
    }
   ],
   "source": [
    "# Vi kan nå teste modellen på nye data\n",
    "predicted_langs = model.predict([\"konstituˈθjon\", \"ɡrʉnlɔʋ\", \"stjourtnar̥skrauːɪn\", \"perusˌtuslɑki\"])\n",
    "print(\"Mest sansynnlige språk for ordene:\", predicted_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mest sansynnlige språk for ordene: ['spansk', 'norsk', 'islandsk', 'finsk']\n",
    "\n",
    "Vet ikke om det er en bug eller hva, men noen ganger sier den rumensk istedenfor norsk.\n",
    "\n",
    "\n",
    "(Svarene bør være spansk, norsk, islandsk og finsk)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oppgave 1.5__: Til slutt kan vi gjennomføre en grundigere evaluering av modellen basert på testsettet. Implementer metoden `evaluate`. Metoden skal beregne og skrive ut de følgende evalueringsmålene:\n",
    "* accuracy (den bør ligge rund 93 % hvis dere har gjort alt riktig.)\n",
    "* precision, recall og $F_1$ for hvert språk\n",
    "* micro- og macro-averaged F1.    \n",
    "    \n",
    "For å beregne disse stallene kan dere bruke metodene fra [`sklearn.metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.937571001397177\n",
      "\n",
      "Precision:\n",
      "['mandarin: 0.9660493827160493', 'japansk: 0.9597026604068858', 'svensk: 0.9225181598062954', 'spansk: 0.9923694779116465', 'islandsk: 0.9564674026244533', 'tysk: 0.9542670477746019', 'arabisk: 0.9784217016029593', 'norsk: 0.9969505997153894', 'rumensk: 0.9103139013452914', 'engelsk: 0.999589995899959', 'swahilisk: 0.7677674084709261', 'koreansk: 0.954349698535745', 'kantonesisk: 0.9383116883116883', 'vietnamesisk: 0.8571428571428571', 'malayisk: 0.7715438210487715', 'fransk: 0.9404081632653061', 'finsk: 0.9564564564564565', 'khmer: 0.8213638012332245', 'farsi: 0.9857549857549858', 'patwa: 0.9746810207336523']\n",
      "\n",
      "Recall:\n",
      "['mandarin: 0.9460004029820673', 'japansk: 0.9845474613686535', 'svensk: 0.9214026602176542', 'spansk: 0.9965718894938496', 'islandsk: 0.9147410358565737', 'tysk: 0.9344262295081968', 'arabisk: 0.9448303234768803', 'norsk: 0.971473851030111', 'rumensk: 0.6403785488958991', 'engelsk: 0.9938850387280881', 'swahilisk: 0.7702556715880446', 'koreansk: 0.9790148000883587', 'kantonesisk: 0.7932296431838975', 'vietnamesisk: 0.3314917127071823', 'malayisk: 0.8499293072106645', 'fransk: 0.9173800517618953', 'finsk: 0.9161073825503355', 'khmer: 0.9288351107465135', 'farsi: 0.966094934184284', 'patwa: 0.9795632137848127']\n",
      "\n",
      "F1:\n",
      "['mandarin: 0.95591978010791', 'japansk: 0.9719663199603765', 'svensk: 0.9219600725952813', 'spansk: 0.9944662440889426', 'islandsk: 0.9351389878831077', 'tysk: 0.9442424242424242', 'arabisk: 0.9613326602725896', 'norsk: 0.9840473562757099', 'rumensk: 0.7518518518518518', 'engelsk: 0.9967293540474242', 'swahilisk: 0.7690095272335071', 'koreansk: 0.9665249154944934', 'kantonesisk: 0.8596926127912743', 'vietnamesisk: 0.47808764940239046', 'malayisk: 0.808841902931283', 'fransk: 0.9287513856696564', 'finsk: 0.9358472086190011', 'khmer: 0.8717998075072184', 'farsi: 0.975825946817083', 'patwa: 0.9771160187868493']\n",
      "\n",
      "F1 micro-averaged: 0.937571001397177\n",
      "\n",
      "F1 macro-averaged: 0.8994576013289187\n"
     ]
    }
   ],
   "source": [
    "def evaluate(self: LanguageIdentifier, transcriptions: list, languages: list) -> None:  \n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "    modellen fungerer ved å beregne:\n",
    "    1) accuracy\n",
    "    2) precision, recall og F1 for hvert språk\n",
    "    3) micro- og macro-averaged F1.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = model.predict(transcriptions)\n",
    "    unique_langs = unique_languages(languages)\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(languages, prediction)\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n",
    "    \n",
    "    prec_rec = sklearn.metrics.precision_recall_fscore_support(languages, prediction)\n",
    "    \n",
    "    precision = [f\"{unique_langs[i]}: {n}\" for i,n in enumerate(prec_rec[0])] # list comprehension som legger til språk foran hver score -> ['kantonesisk: 0.9591753419065115', ...]\n",
    "    print(f\"Precision:\\n{precision}\\n\")\n",
    "    \n",
    "    recall = [f\"{unique_langs[i]}: {n}\" for i,n in enumerate(prec_rec[1])]\n",
    "    print(f\"Recall:\\n{recall}\\n\")\n",
    "    \n",
    "    f1score = sklearn.metrics.f1_score(languages, prediction, average=None)\n",
    "    f1 = [f\"{unique_langs[i]}: {n}\" for i,n in enumerate(f1score)]\n",
    "    print(f\"F1:\\n{f1}\\n\")\n",
    "    \n",
    "    f1_micro = sklearn.metrics.f1_score(languages, prediction, average='micro')\n",
    "    print(f\"F1 micro-averaged: {f1_micro}\\n\")\n",
    "    \n",
    "    f1_macro = sklearn.metrics.f1_score(languages, prediction, average='macro')\n",
    "    print(f\"F1 macro-averaged: {f1_macro}\")\n",
    "    \n",
    "LanguageIdentifier.evaluate = evaluate\n",
    " \n",
    "# Vi kan nå evaluere hvor godt modellen fungerer på testsett\n",
    "model.evaluate(test_data.IPA.values, test_data.språk.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse av modellen\n",
    "\n",
    "Hva har modellen egentlig lært? En stor fordel med logistisk regresjon er at modellene er relativt enkle å tolke: Hvis en vekt $w_i$ i modellen har stor positiv verdi betyr det at sannsynnlighet for outputklassen _øker_ sammen med trekket $x_i$.  Likeledes betyr en negativ verdi at sannsynlighet for outputklassen _reduseres_ med større verdier av $x_i$. Og jo større vektet er (positiv eller negativ), jo større er effekten. \n",
    "\n",
    "Vi kan inspisere modellen vår for å finne ut hvilke språklyder som har størst effekt på prediksjonene. I `scikit-learn` er modellvektene lagret i variabelen `coef_` (merk underscoren ved slutten). Siden modellen vår er multiklasse (med 20 unike språk) og inneholder $m \\approx 155$ trekk er vektene i `coef_` en matrise av dimensjon $(20,m)$. \n",
    "\n",
    "__Oppgave 1.6a__: Finn ut hvilket fonetisk symbol som bidrar mest til å øke sannsynnligheten for at et ord er klassifisert som norsk. Sjekk om det gir mening ved å telle hvor ofte symbolet forekommer i et norsk ord vs. ikke-norsk ord.\n",
    "\n",
    "__Oppgave 1.6b__: Finn ut hvilket fonetisk symbol som bidrar mest til å redusere sannsynnligheten for at et ord er klassifisert som norsk.\n",
    "\n",
    "Søk gjerne på nettet for å finnes ut hva disse fonetiske symbolene egentlig står for hvis du er interessert!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolet som øker sannsynligheten mest for at et ord er klassifisert som norsk: ʋ\n",
      "Symbolet som reduserer sannsynligheten mest for at et ord er klassifisert som norsk: ²\n"
     ]
    }
   ],
   "source": [
    "unique_symbols = model._extract_unique_symbols(transcriptions)\n",
    "\n",
    "norsk_coef = model.model.coef_[map_languages(languages, ['norsk'])].tolist()\n",
    "print(f\"Symbolet som øker sannsynligheten mest for at et ord er klassifisert som norsk: {unique_symbols[norsk_coef.index(max(norsk_coef))]}\")\n",
    "print(f\"Symbolet som reduserer sannsynligheten mest for at et ord er klassifisert som norsk: {unique_symbols[norsk_coef.index(min(norsk_coef))]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 2: sekvensmodellering\n",
    "\n",
    "Vi skal nå jobbe på en viktig anvendelse av sekvensmodeller, nemlig å gjenkjenne navngitte entiteter (_Named Entity Recognition_ eller NER på engelsk). For å gjøre det så enkelt som mulig vil vi bruke en _Hidden Markov Model_ som sekvensmodell. Hvert ord skal assosieres med en bestemte klasse, og vi skal ta i bruk såkalt BIO-annotering (også kalt IOB i boken til Jurafsky og Martin) for å spesifisere hvilke som ord hører til en navngitt entitet. \n",
    "\n",
    "_NB_: I praksis er ikke HMM den mest hensiktsmessige sekvensmodellen for å gjenkjenne navngitte enheter. Andre modeller slik som _transformers_ vil være bedre egnet til denne oppgaven, med disse modellene er betydelige mer kompliserte å trene. \n",
    "\n",
    "\n",
    "### Data \n",
    "Vi skal trene modellen med dataene i `norne_train.txt`. Filen inneholder tokeniserte setninger (en per linje) hvor de navngitte entitetene er markert med XML-tags, som f.eks:\n",
    "\n",
    "```xml\n",
    "De første 43 minuttene hadde <ORG>Rosenborg</ORG> all makt og \n",
    "tilnærmet full kontroll på <LOC>Fredrikstad Stadion</LOC> .\n",
    "```\n",
    "I eksempelet over har vi 2 navngitte enheter, _Rosenborg_ (en organisasjon) og _Fredrikstad Stadion_ (et sted).\n",
    "\n",
    "Vi har allerede implementert en funksjon `preprocess` som tar en tekst som input (som f.eks. setningene i trening- eller testsett) og ekstraherer lister over setninger og navngitte entiteter i disse setningene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['De',\n",
       "   'første',\n",
       "   '43',\n",
       "   'minuttene',\n",
       "   'hadde',\n",
       "   'Rosenborg',\n",
       "   'all',\n",
       "   'makt',\n",
       "   'og',\n",
       "   'tilnærmet',\n",
       "   'full',\n",
       "   'kontroll',\n",
       "   'på',\n",
       "   'Fredrikstad',\n",
       "   'Stadion',\n",
       "   '.']],\n",
       " [[(5, 6, 'ORG'), (13, 15, 'LOC')]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oblig1b_utils\n",
    "oblig1b_utils.preprocess(\"De første 43 minuttene hadde <ORG>Rosenborg</ORG> all makt og \" +\n",
    "                         \"tilnærmet full kontroll på <LOC>Fredrikstad Stadion</LOC> .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De navngitte entitetene er spesifisert som tupler $(i, j, tag)$ hvor $i$ er indeksen for starten av entiteten, $j$ er indeksen for slutten, og $tag$ er entitetstypen, som f.eks. ORG eller LOC. Indekstallene er på ordnivå:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassen\n",
    "\n",
    "Her er skjelettet for `NamedEntityRecogniser`-klassen  som skal implementeres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oblig1b_utils\n",
    "\n",
    "class NamedEntityRecogniser:\n",
    "    \"\"\"Gjenkjenning av navngitte enheter ved bruk av HMM\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Intialiserer alle variablene som er nødvendig for å representere og \n",
    "        estimere  sekvensmodellen (en Hidden Markov Model) som brukes til å \n",
    "        gjenkjenne de navngitte enhetene\"\"\"\n",
    "        \n",
    "        # alle labellene som forekommer i treningsettet\n",
    "        self.labels = set()\n",
    "\n",
    "        # alle token som forekommer i treningsettet\n",
    "        self.vocab = set()\n",
    "\n",
    "        # hvor mange ganger en label (f.eks. B-ORG) forekommer i treningsettet\n",
    "        self.label_counts = {}  \n",
    "\n",
    "        # hvor mange overgang fra label_1 til label2 forekommer i treningsettet\n",
    "        self.transition_counts = {}\n",
    "        \n",
    "        # hvor mange \"utslipp\" fra label til token forekommer i treningsettet\n",
    "        # (Merk at vi legger et spesielt symbol for ord som aldri forekommer\n",
    "        # i treningsettet, men kan forekomme i testsettet)\n",
    "        self.emission_counts = {(\"O\", \"<UNK>\"):1}\n",
    "                \n",
    "        # Sansynnlighet P(label_2 | label_1)\n",
    "        self.transition_probs = {}\n",
    "        \n",
    "        # Sansynnlighet P(token | label)\n",
    "        self.emission_probs = {}\n",
    "    \n",
    "    \n",
    "    def fit(self, tagged_text):\n",
    "        \"\"\"Estimerer tallene og sansynnlighetene for HMM, basert på (tokenisert)\n",
    "        tekst hvor navngitte enhetene er markert med XML tags (se norne.txt)\"\"\"\n",
    "        \n",
    "        # Ekstrahere setninger og navngitte enheter markert i hver setning\n",
    "        sentences, all_spans = oblig1b_utils.preprocess(tagged_text)\n",
    "                \n",
    "        for sentence, spans in zip(sentences, all_spans):\n",
    "     \n",
    "            # Ekstrahere labelsekvenser, med BIO marking\n",
    "            label_sequence = get_BIO_sequence(spans, len(sentence))\n",
    "                                              \n",
    "            # Oppdatere tallene \n",
    "            self._add_counts(sentence, label_sequence)\n",
    "            \n",
    "        # Beregne sansynnlighetene (transition og emission) ut fra tallene\n",
    "        self._fill_probs()\n",
    "                   \n",
    "        \n",
    "    def _add_counts(self, sentence, label_sequence):\n",
    "        \"\"\"Oppdaterer variablene self.vocab, self.labels, self.label_counts, \n",
    "        self.transition_counts og  self.emission_counts, basert på setningen og \n",
    "        sekvenslabellen assosiert med dem. \n",
    "        Merk at setningen og label_sequence har samme lengde.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _fill_probs(self, alpha_smoothing=1E-6):\n",
    "        \"\"\"Beregne sannsynlihetsfordelinger self.transition_probs og\n",
    "        self.emission_probs basert på tallene som er samlet inn i \n",
    "        self.label_counts, self.transition_counts og self.emission_counts.\n",
    "        \n",
    "        Når det gjeler self.emission_probs bør vi legge Laplace smoothing, med en\n",
    "        verdi for alpha som er alpha_smoothing.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "            \n",
    "    \n",
    "    def _beam_search(self, sentence):\n",
    "        \"\"\"Kjører beam-search på setningen (liste over tokens) og\n",
    "        returnerer to outputs: \n",
    "        1) en labelsekvens (som har samme lengde som setningen)\n",
    "        2) sansynnlighet for hele sekvensen \"\"\"\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "                \n",
    "    def label(self, text):\n",
    "        \"\"\"Gitt en tokenisert tekst, finner ut navngitte enheter og markere disse\n",
    "        med XML tags. \"\"\"\n",
    "        sentences, _ = oblig1b_utils.preprocess(text)\n",
    "        spans = []\n",
    "        for sentence in sentences:\n",
    "            sentence = [token if token in self.vocab else \"<UNK>\" for token in sentence]\n",
    "            label_sequence, _ = self._beam_search(sentence)\n",
    "            spans.append(oblig1b_utils.get_spans(label_sequence))\n",
    "        \n",
    "        return oblig1b_utils.postprocess(sentences, spans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO-markering\n",
    "\n",
    "\n",
    "For å trene en HMM må hvert ord kobles til en merkelapp (_label_). En vanlig måte å gjøre dette er å bruke en såkalt BIO-markering, hvor hvert ord markeres som:\n",
    "* 'O' (hvis ordet ikke tilhører en navngitt entitet)\n",
    "* 'B-X' (hvis ordet er det første ordet i en navngitt entitet av type 'X')\n",
    "* 'I-X' (hvis ordet tilhører en entitet av type 'X', men ikke er det første ordet)\n",
    "\n",
    "__Oppgave 2.1__: Implementer funksjonen _get_BIO_sequence_ som tar som input en liste med ``text spans'' og setningslengden og gir tilbake en rekke (av samme lengde som setningen) med BIO-markeringer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_BIO_sequence(spans, sentence_length):\n",
    "    \"\"\"Gitt en liste over \"spans\", representert som tuples (start, end, tag),\n",
    "    og en setningslengde, produserer en sekvens med BIO (også kalt IOB) labeller\n",
    "    for setningen. \n",
    "    Eksempel: hvis spans=[(1,3,'ORG')] og sentence_length=6 bør resultatet være\n",
    "    ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']\"\"\"\n",
    "    \n",
    "    # Implementer metoden her!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Telling\n",
    "\n",
    "Som vi så i forelesningen er Hidden Markov Models definert med en vokabular (som tilsvarer ``observasjonene''), et sett mulig merkelapp (de skjulte tilstandene), og to sannsynlighetsfordelinger:\n",
    "* Den første fordelingen er kalt transisjonsmodell og definert som $P(label_t | label_{t-1})$. Transisjonsmodellen forteller oss hvor sannsynlig det er at $label_{t-1}$ (assosiert med ord $w_{t-1}$) følges av $label_t$ (assosiert med ord $w_t$). \n",
    "* Den andre fordelingen er emisjonsmodellen, definert som $P(w_t | label_t)$. Emisjonsmodellen forteller oss hvor sannsynlig det er å observere ordet $w_t$ hvis merkelappen for dette ordet er $label_t$.\n",
    "\n",
    "For å estimere disse to sannsynlighetsfordelinger må vi telle:\n",
    "* Alle ordene som forekommer i treningssettet\n",
    "* Alle BIO-labels som forekommer i treningssettet\n",
    "* Antall ganger hver BIO-label forekommer i treningssettet\n",
    "* Antall ganger to BIO-labels følger hverandre i treningssettet\n",
    "* Antall ganger et ord er observert med en BIO-label i treningssettet\n",
    "\n",
    "__Oppgave 2.2__: Implementer metoden `_add_counts` som oppdaterer variablene som inneholder disse tallene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def _add_counts(self, sentence, label_sequence):\n",
    "    \"\"\"Oppdaterer variablene self.vocab, self.labels, self.label_counts, \n",
    "    self.transition_counts og  self.emission_counts, basert på setningen og \n",
    "    sekvenslabellene assosiert med dem. \n",
    "    Merk at setningen og label_sequence må ha samme lengde.\"\"\"\n",
    "        \n",
    "    # Implementer metoden her!\n",
    "    \n",
    "NamedEntityRecogniser._add_counts = _add_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sannsynligheterfordelinger\n",
    "\n",
    "Med hjelp av disse tallene kan vi nå estimere transisjonsmodellen og emisjonsmodellen. For emisjonsmodellen bør dere legge til _Laplace smoothing_ for å gjøre modellen mer robust, da treningssettet er relativt lite. La oss si at $C(label)$ er antall ganger BIO-merkelappen $label$ ble observert, og $C(label, token)$ antall ganger ordet $token$ ble observert sammen med $label$.  Ved hjelp av Laplace smoothing definerer vi sannsynligheten $P(token | label)$ slik:\n",
    "\n",
    "$$\n",
    "P(token | label) = \\frac{C(label, token) + \\alpha}{C(label) + \\alpha V}\n",
    "$$\n",
    "\n",
    "hvor $V$ er størrelsen på vokabularet. \n",
    "\n",
    "__Oppgave 2.3__: Implementer metoden `_fill_probs` som beregner transisjonsmodellen og emisjonsmodellen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_probs(self, alpha_smoothing=1E-6):\n",
    "    \"\"\"Beregne sannsynlihetsfordelinger self.transition_probs og\n",
    "    self.emission_probs basert på tallene som er samlet inn i \n",
    "    self.label_counts, self.transition_counts og self.emission_counts.\n",
    "        \n",
    "    Når det gjeler self.emission_probs bør vi legge Laplace smoothing, med en\n",
    "    verdi for alpha som er alpha_smoothing.\"\"\"\n",
    "        \n",
    "    # Implementer metoden her!\n",
    "    \n",
    "NamedEntityRecogniser._fill_probs = _fill_probs            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og vi kan nå trene modellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the model\n",
    "with open(\"norne_train.txt\") as fd:\n",
    "    model = NamedEntityRecogniser()\n",
    "    training_texts = fd.read()\n",
    "    model.fit(training_texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dekoding med beam search\n",
    "\n",
    "Til slutt skal vi implementere metoden `_beam_search` som skal finne den mest sannsynlige label-sekvensen for en setning ved hjelp av beam-search-algoritmen. \n",
    "\n",
    "Vi har sett hvordan beam search fungerer i forelesningen. Kort fortalt består et _beam_ av en mengde _hypoteser_, hvor en hypotese representerer her en mulig sekvens av BIO-labeller for setningen. Vi bygger opp disse hypotesene ord etter ord, inntil alle ordene er behandlet. I beam-search begrenser vi antall hypoteser som kan lagres etter hvert steg (=_beam width_) for å unngå en kombinatorisk eksplosjon.\n",
    "\n",
    "__Oppgave 2.4__: Implementer metoden `_beam_search`. For å gjøre det litt lettere er metoden allerede delvis implementert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _beam_search(self, sentence, beam_width=3):\n",
    "    \"\"\"Kjører beam search på setningen (liste over tokens), og\n",
    "    returnerer to outputs: \n",
    "    1) en labelsekvens (som har samme lengde som setningen)\n",
    "    2) sansynnlighet for hele sekvensen \"\"\"\n",
    "\n",
    "    # Vi starter med en beam som består av én tom hypotese\n",
    "    # Hver hypotese i beam består av to elementer:\n",
    "    # -'labels' er en liste over BIO-labels (en label per ord i setningen)\n",
    "    # -'prob' er sannsynligheten for denne labelsekvensen\n",
    "    beam = [{\"labels\":[], \"prob\":1.0}]\n",
    "\n",
    "    for token in sentence:\n",
    "        # Her må vi lage nye hypoteser som utvider de eksisterende\n",
    "        # hypotesene i beam med BIO-labeller for token\n",
    "        # (OBS: antall hypoteser i beam må ikke overstige beam_width)\n",
    "        raise NotImplementedError() \n",
    "        \n",
    "    # Vi velger hypotesen med høyest sannsynlighet\n",
    "    best_hypothesis = sorted(beam, key=lambda x : x[\"prob\"])[-1]\n",
    "\n",
    "    # Og returnerer labelsekvensen og dens sannsynlighet\n",
    "    return best_hypothesis[\"labels\"], best_hypothesis[\"prob\"]\n",
    "\n",
    "NamedEntityRecogniser._beam_search = _beam_search            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når dere har implementert modellen ferdig kan dere teste ut hvordan den fungerer ved å kalle metoden `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the model to a sample sentence\n",
    "model.label(\"Kjell Magne Bondevik var statsminister i Norge .\")\n",
    "# Forventet svar: '<PER>Kjell Magne Bondevik</PER> var statsminister i <GPE>Norge</GPE> .'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valgfritt spørsmål (for de modigste)\n",
    " \n",
    "Det er ofte en dårlig idé å gange mange små sannsynligheter, da vi kan havne i numerisk _underflow_. En vanlig løsning er å benytte log-sannsynligheter som kan summeres i stedet for å multipliseres, slik som forklart [her](http://www.cs.columbia.edu/~mcollins/cs4705-fall2018/notes-on-logs.pdf).\n",
    "\n",
    "__Oppgave 2.5__: Prøv å implementere beam search algoritmen med log-sannsynligheter.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3529d1d89cb4c8d13e402e4117b8dc865480f261d07f0716e8c60a591b54d3ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
