{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN2110 obligatorisk innlevering 1b\n",
    "\n",
    "Oppgaven har to deler, logistisk regresjon for å klassifisere språk basert på IPA lydskrift, og Named Entity Recognition med HMM. Det er en god idé å lese gjennom hele oppgavesettet før du setter i gang. \n",
    "\n",
    "Dersom du har spørsmål så kan du:\n",
    "\n",
    "* gå på gruppetime,\n",
    "* spørre på Discourse\n",
    "* eller sende epost til in2110-hjelp@ifi.uio.no dersom alternativene over av en eller annen grunn ikke passer for spørsmålet ditt.\n",
    "\n",
    "### Oppsett\n",
    "Når du har klonet dette github-repoet som denne notebooken ligger i, har du tilgang til datene og hjelpefilene som ligger i denne mappa. Hvis du ønsker å kopiere denne mappa, \"1b\", over til et annet sted, så skulle det gå bra. Bare pass på at du følger med på om det er oppdateringer her i repoet som gir ut obligen. Når du har aktivert in2110-miljøet med conda, så har du tilgang til pakkene som trengs for å kjøre denne notebooken. Vi har forberedt en notebook med all prekoden, der du også kan fylle ut din kode og kjøre prosessene.\n",
    "\n",
    "### Innlevering\n",
    "\n",
    "Innleveringen skal helst bestå av denne Jupyter notebook fylt ut med både kode og tilhørende forklaringer. Vi understreker at innlevering av koden alene __ikke er nok__ for å bestå oppgaven -- vi forventer at notebooken også skal inneholde _beskrivelser_ (på norsk eller engelsk) av hva dere har gjort og _begrunnelser_ for valgene dere har tatt underveis. Bruk helst hele setninger, og matematiske formler om nødvendig. Evalueringstallene bør presenteres i tabeller. Det å  forklare med egne ord (samt begreper vi har gått gjennom på forelesningene) hva dere har implementert og reflektere over hvorvidt løsningen dere har lagt  besvarer oppgaven er en viktig del av læringsprosessen -- ta det på alvor! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 1: Logistisk regresjon\n",
    "\n",
    "\n",
    "I den første delen av innleveringen skal vi bruke logistisk regresjon til å utvikle en enkel _språkidentifikator_, dvs. et lite system som skal predikere hvilket språk et ord hører til. Mer spesifikk skal systemet ta ordets _fonetiske transkripsjon_ som input og returnere _navnet på språket_ som ordet mest sannsynlig tilhører.  Systemet skal for eksempel kunne ta transkripsjonen [bʊndɛsvɛɾfaszʊŋ] som input og returnere ``tysk''. \n",
    "\n",
    "## Data\n",
    "\n",
    "For å trene modellen (dvs. finne ut verdier for vektene og skjæringspunktene basert på data) skal vi ta i bruk eksisterende lister over ord med deres fonetiske transkripsjon i såkalt _IPA_-format (IPA står for _[International Phonetic Alphabet](https://upload.wikimedia.org/wikipedia/commons/8/8e/IPA_chart_2018.pdf)_).  Dere trenger ikke å kunne lese eller skrive slike fonetiske transkripsjoner i denne oppgaven. Det viktigste er å forstå at disse transkripsjonene beskriver språklydene som utgjør ordet, samt andre egenskaper slik som lengde, tone, trykk og intonasjon. Fonetiske transkripsjoner forteller oss hvordan et ord bør uttales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached file from ./langid_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treningsett: 689238 eksempler, testsett: 76583 eksempler\n"
     ]
    }
   ],
   "source": [
    "import oblig1b_utils \n",
    "train_data, test_data = oblig1b_utils.extract_wordlist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data vi skal bruke er lagt i to `DataFrame` tabeller: et treningsett med 90 % av ordene og et testsett med de resterende 10 %. Ordene fra de forskjellige språkene er blandet i disse to tabellene. `DataFrame` er en datastruktur fra Python-biblioteket [`pandas`](https://pandas.pydata.org) og representerer en slags tabell med kolonner og rader. Biblioteket `pandas` gjør det lett å visualisere og manipulere slike tabeller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistikk over språkene i treningsett:\n",
      "språk\n",
      "koreansk        45051\n",
      "spansk          45031\n",
      "vietnamesisk    45025\n",
      "rumensk         45022\n",
      "japansk         45020\n",
      "finsk           45012\n",
      "kantonesisk     45009\n",
      "tysk            45001\n",
      "fransk          44989\n",
      "engelsk         44961\n",
      "islandsk        44959\n",
      "arabisk         44947\n",
      "swahilisk       43537\n",
      "mandarin        40357\n",
      "malayisk        25298\n",
      "svensk          18971\n",
      "norsk            9136\n",
      "farsi            7275\n",
      "khmer            2945\n",
      "patwa            1692\n",
      "Name: count, dtype: int64\n",
      "Første 30 ord:\n",
      "                     ord                  IPA         språk\n",
      "618012          Urheimat       ˈuːɐ̯ˌhaɪ̯maːt          tysk\n",
      "568297                扫荡         sɑʊ˨˩˦ tɑŋ˥˩      mandarin\n",
      "616785           lứa đôi          lɯə˩˧ doj˧˥  vietnamesisk\n",
      "197624           berdebu              bərdəbu      malayisk\n",
      "88181        convenciste          kombenθiste        spansk\n",
      "198963               숫돼지       sʰut̚t͈wɛ̝d͡ʑi      koreansk\n",
      "288725            points             pˈɔ‍ɪnts       engelsk\n",
      "25148          henniront              ʼeniʁɔ̃        fransk\n",
      "23713        fichándolas         fiˈtʃandolas        spansk\n",
      "203591                 坨               tʰuɔ˧˥      mandarin\n",
      "500822              출썩대다  t͡ɕʰuɭs͈ʌ̹k̚t͈ɛ̝da̠      koreansk\n",
      "639644   desajustaríamos     desaxustaˈɾiamos        spansk\n",
      "169169            gisten            ²jˈɪsːtɛn        svensk\n",
      "427300       cabestrearé         kaβestɾeaˈɾe        spansk\n",
      "569472      mendémpétkan         məndempetkan      malayisk\n",
      "609994         amovibles              amɔvibl        fransk\n",
      "110005          assénons               asenɔ̃        fransk\n",
      "653176  maarekisterinote  ˈmɑɑreˌkisteˌrinote         finsk\n",
      "2804                khớp                xɤp˦˥  vietnamesisk\n",
      "499034   eclesiastizabas      eklesjastiθaβas        spansk\n",
      "636655          ascuțime            askutsime       rumensk\n",
      "307642          verrönnt            fɛɐ̯ˈʁœnt          tysk\n",
      "688314           kupokea              kupokea     swahilisk\n",
      "764247             RIFFI               rˈɪfːɪ        svensk\n",
      "476929           rămânea              rəmɨnĕa       rumensk\n",
      "364460        ピピン・アットマーク      pipiɴ atːomaːkɯ       japansk\n",
      "129868          gấp ngày         ɣɤ̆p˦˥ ŋăj˦˨  vietnamesisk\n",
      "50136            tampian              tampian      malayisk\n",
      "676855                传染      ʈʂʰwan˧˥ ʐan˨˩˦      mandarin\n",
      "486405                악부              a̠k̚p͈u      koreansk\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistikk over språkene i treningsett:\")\n",
    "print(train_data.språk.value_counts())\n",
    "print(\"Første 30 ord:\")\n",
    "print(train_data[:30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassen\n",
    "\n",
    "Her er skjelettet for `LanguageIdentifier`-klassen  som skal implementeres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "class LanguageIdentifier:\n",
    "    \"\"\"Logistisk regresjonsmodell som tar IPA transkripsjoner av ord som input, \n",
    "    og predikerer hvilke språkene disse ordene hører til.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialiser modellen\"\"\"      \n",
    "        # selve regresjonsmodellen (som brukes all CPU-er på maskinen for trening)\n",
    "        self.model = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", multi_class='ovr')\n",
    "    \n",
    "    def train(self, transcriptions, languages):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "        den logistisk regresjonsmodellen. De to rekkene må ha samme lendgen\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "        for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "        \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "        symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _extract_feats(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "        hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def evaluate(self, transcriptions, languages):  \n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "        modellen fungerer ved å beregne:\n",
    "        1) accuracy\n",
    "        2) precision, recall og F1 for hvert språk\n",
    "        3) micro- og macro-averaged F1.\n",
    "        \"\"\"\n",
    "        \n",
    "        # See API fra sklearn.metrics for å finne ut hvordan dette kan gjøres! \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening \n",
    "Vi skal benytte oss av en logistisk regresjonsmodell, mer spesifikk klassen [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) fra `scikit-learn`. Men for å kunne bruke modellen må vi naturligvis først estimere parametrene basert på treningsdata. \n",
    " Hva slags trekk (_features_) skal vi bruke i modellen vår? I denne oppgaven skal vi gjøre det enkelt for oss selv, og kun ta i betrakning forekomst av bestemte IPA-symboler som identifiserer ordlyder i den fonetiske transkripsjonen av ordet. _NB_: hvis du kan litt fonetikk fra før vil dere kanskje stusse på denne overforenklingen, da IPA-symboler brukes til å kode en god del andre egenskaper knyttet til talelyder slik som lengde, tone, trykk og intonasjon. Men i denne oppgaven skal vi gå den enkle veien og bruke alle symbolene i disse transkripsjonene uten å skille mellom ulike typer.\n",
    "\n",
    "Trekkene vil ha binære verdier (1 hvis transkripsjonen inneholder symbolet og 0 ellers) og kan sees som en slags ``bag-of-sounds'', siden de vil fortelle oss hvilke ordlyder som forekommer i ordet, men ikke i hvilken rekkefølge.\n",
    "\n",
    "__Opgave 1.1:__ Det første skrittet er å lage en liste over alle IPA-symboler som finnes i treningsettet. Metoden `_extract_unique_symbols` skal ta de fonetiske transkripsjonene fra treningssettet som input, og returnere en liste med alle fonetiske symboler (altså tegn) som finnes i disse transkripsjonene og forekommer minst 10 ganger. Implementer denne metoden. Antall symboler kan variere litt avhengig av den tilfeldige inndelingen mellom treningsettet og testsettet, men bør ligge på rundt 155 unike symboler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "    \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "    symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "    \n",
    "    symbols = {}\n",
    "    for word in transcriptions:\n",
    "        for symbol in word:\n",
    "            if symbol not in symbols:\n",
    "                symbols[symbol] = 0\n",
    "            symbols[symbol] += 1\n",
    "    \n",
    "    result = [symbol for symbol, n in symbols.items() if n > min_nb_occurrences]\n",
    "    return result\n",
    "    \n",
    "# her kobler vi metoden vi har implementert til klassen\n",
    "LanguageIdentifier._extract_unique_symbols = _extract_unique_symbols \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Oppgave 1.2__: Deretter må vi implementere metoden `_extract_feats` som tar en liste fonetiske transkripsjoner og returnerer en matrise $X$ hvor hver rad tilsvarer en transkripsjon og hver kolonne representerer et bestemt trekk. La oss si vi har $m$ unike fonetiske symboler (ekstrahert med metoden ovenfor), og får en liste med $n$ fonetiske transkripsjoner $T = \\{t_i \\text{ hvor } 0 < i < n\\}$. Metoden `_extract_feats(transcriptions)` må returnere en matrise $X$ av dimensjon $(n,m)$, hvor hver matrisecelle $X_{ij}$ er definert slik: \n",
    "\n",
    "$$\n",
    "X_{ij}  =  \\begin{cases} 1 \\text{  hvis symbolet } j \\text{ forekommer i transkripsjonen } t_i \\\\\n",
    "0 \\text{  ellers} \\end{cases} \n",
    "$$\n",
    "\n",
    "Tips: den enkleste fremgangsmåten kan være å starte med å lage en tom matrise slik som `X = np.zeros(n,m)` og deretter endre cellene hvor `X[i,j]` skal ha 1 som verdi i stedet for 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _extract_feats(self, transcriptions, unique_symbols: list = []):\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "    hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\n",
    "    Kan ta inn en liste symboler (brukes når man skal predicte).\"\"\"\n",
    "    \n",
    "    if len(unique_symbols) == 0:\n",
    "        unique_symbols = _extract_unique_symbols(self, transcriptions)\n",
    "    \n",
    "    m = len(unique_symbols)\n",
    "    n = len(transcriptions)\n",
    "    X = np.zeros((n, m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if unique_symbols[j] not in transcriptions[i]:\n",
    "                continue\n",
    "            X[i][j] = 1\n",
    "    \n",
    "    return X\n",
    "\n",
    "LanguageIdentifier._extract_feats = _extract_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oppgave 1.3__: Vi er nå klare til for å implementere funksjonen `train`. Metoden tar to lister som input, en liste fonetiske transkripsjoner og en liste med språknavn (de to listene må ha samme lengde). Metoden skal trene den logistiske regresjonsmodellen `self.model` ved å kalle `fit(X, y)`, hvor `X` er en matrise med alle trekk ekstrahert med metoden `_extract_feats`, og `y` er outputklassene. \n",
    "\n",
    "Merk at `scikit-learn` krever at outputklassene `y` må være en liste med heltall (og ikke strenger). Det betyr at dere må lage en mapping mellom språknavn og heltall (f.eks. ved å si at \"norsk\" er 0, \"arabisk\" er 1, \"finsk\" er 2, osv.). Når dere har både matrisen `X` og output `y` er det bare å kalle metoden `fit(X, y)` for å trene modellen. Trening kan ta noen minutter avhengig av maskinen deres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_languages(languages: list) -> list:\n",
    "    \"\"\"Gitt en rekke med språk, returnerer en rekke med unike språk.\"\"\"\n",
    "    \n",
    "    unique_langs = []\n",
    "    for l in languages:\n",
    "        if l not in unique_langs:\n",
    "            unique_langs.append(l)\n",
    "    \n",
    "    return unique_langs\n",
    "\n",
    "def map_languages(languages: list, mapped: list = []) -> list:\n",
    "    \"\"\"Metode som tar inn en rekke med språk og mapper de til hvert sitt heltall. \n",
    "    Man kan også decode hvilket språk en liste heltall er ved å sende inn språklisten og listen med tall som parametre.\"\"\"\n",
    "    \n",
    "    res = [x for x in languages]\n",
    "    unique_langs = unique_languages(languages)\n",
    "    \n",
    "    for i, l in enumerate(res):\n",
    "        res[i] = unique_langs.index(l)\n",
    "    \n",
    "    if len(mapped) == 0:\n",
    "        return res\n",
    "    \n",
    "    if len(mapped) == 1:\n",
    "        mapped = mapped[0]\n",
    "        return unique_langs.index(mapped)\n",
    "    \n",
    "    return [unique_langs[x] for x in mapped]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self: LanguageIdentifier, transcriptions: list, languages: list) -> None:\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "    den logistisk regresjonsmodellen. De to rekkene må ha samme lengde.\"\"\"\n",
    "    \n",
    "    X = _extract_feats(self, transcriptions)\n",
    "    y = map_languages(languages)\n",
    "    \n",
    "    self.model.fit(X, y)\n",
    "\n",
    "LanguageIdentifier.train = train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi er nå klare til å trene modellen (kan ta noen minutter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageIdentifier()\n",
    "transcriptions = train_data.IPA.values\n",
    "languages = train_data.språk.values\n",
    "model.train(transcriptions, languages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prediksjon og evaluering\n",
    "\n",
    "Når modellen er trent kan vi anvende den på nye fonetiske transkripsjoner. \n",
    "\n",
    "__Oppgave 1.4__: Implementer metoden `predict`. Metoden tar som input en liste fonetiske transkripsjoner og predikerer det mest sannsynlige språket for hver transkripsjon. Listen som returneres må ha samme lengde som inputlisten. Husk at `scikit-learn` opererer med outputklasser representert som heltall, så dere må forvandle disse tallene tilbake til språknavnene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self: LanguageIdentifier, transcriptions: list) -> list:\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "    for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "    \n",
    "    all_symbols = _extract_unique_symbols(self, train_data.IPA.values)\n",
    "    feats = _extract_feats(self, transcriptions, all_symbols) # extracter feats med samme symboler som treningssettet så matrisen av feats blir riktig\n",
    "    preds = self.model.predict(feats)\n",
    "    preds = map_languages(languages, preds)\n",
    "    return preds\n",
    "\n",
    "LanguageIdentifier.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deretter kan dere se hvordan modellen fungerer i praksis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mest sansynnlige språk for ordene: ['spansk', 'norsk', 'islandsk', 'finsk']\n"
     ]
    }
   ],
   "source": [
    "# Vi kan nå teste modellen på nye data\n",
    "predicted_langs = model.predict([\"konstituˈθjon\", \"ɡrʉnlɔʋ\", \"stjourtnar̥skrauːɪn\", \"perusˌtuslɑki\"])\n",
    "print(\"Mest sansynnlige språk for ordene:\", predicted_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det virker som om det er 50/50 om modellen predikerer norsk eller rumensk. Accuracy-en til modellen er likevel 93%, og den greier de andre språkene hver gang.\n",
    "\n",
    "\n",
    "(Svarene bør være spansk, norsk, islandsk og finsk)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oppgave 1.5__: Til slutt kan vi gjennomføre en grundigere evaluering av modellen basert på testsettet. Implementer metoden `evaluate`. Metoden skal beregne og skrive ut de følgende evalueringsmålene:\n",
    "* accuracy (den bør ligge rund 93 % hvis dere har gjort alt riktig.)\n",
    "* precision, recall og $F_1$ for hvert språk\n",
    "* micro- og macro-averaged F1.    \n",
    "    \n",
    "For å beregne disse stallene kan dere bruke metodene fra [`sklearn.metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9372315004635493\n",
      "\n",
      "Precision:\n",
      "['islandsk: 0.9636990468464814', 'fransk: 0.965181871231278', 'koreansk: 0.943609022556391', 'svensk: 0.9920031987205118', 'kantonesisk: 0.9604959025005253', 'swahilisk: 0.9492203118752499', 'arabisk: 0.9755395683453237', 'spansk: 0.9963197710079739', 'tysk: 0.9439655172413793', 'malayisk: 0.9989835332384631', 'vietnamesisk: 0.758985200845666', 'finsk: 0.950592885375494', 'rumensk: 0.9186550976138829', 'engelsk: 0.8522727272727273', 'japansk: 0.7672256653299308', 'mandarin: 0.9416683663063431', 'khmer: 0.9612555174104953', 'norsk: 0.8234086242299795', 'farsi: 0.9859183673469388', 'patwa: 0.9771993543179984']\n",
      "\n",
      "Recall:\n",
      "['islandsk: 0.9404314268751237', 'fransk: 0.9851101846337106', 'koreansk: 0.9261992619926199', 'svensk: 0.9947874899759422', 'kantonesisk: 0.9121931750149671', 'swahilisk: 0.9418766117833763', 'arabisk: 0.9530120481927711', 'spansk: 0.9763574433981166', 'tysk: 0.6422287390029325', 'malayisk: 0.9929278642149929', 'vietnamesisk: 0.7386831275720165', 'finsk: 0.9787474564775039', 'rumensk: 0.8183574879227054', 'engelsk: 0.42134831460674155', 'japansk: 0.8456901748040988', 'mandarin: 0.9291607969410344', 'khmer: 0.9176029962546817', 'norsk: 0.9245441207294068', 'farsi: 0.9663932786557311', 'patwa: 0.9734673366834171']\n",
      "\n",
      "F1:\n",
      "['islandsk: 0.9519230769230769', 'fransk: 0.9750442130084496', 'koreansk: 0.9348230912476723', 'svensk: 0.9933933933933934', 'kantonesisk: 0.9357215967246673', 'swahilisk: 0.9455342029274122', 'arabisk: 0.9641442356526155', 'spansk: 0.9862376037239425', 'tysk: 0.7643979057591623', 'malayisk: 0.9959464937170652', 'vietnamesisk: 0.7486965589155371', 'finsk: 0.9644647432327057', 'rumensk: 0.8656106285130302', 'engelsk: 0.5639097744360902', 'japansk: 0.8045493644270285', 'mandarin: 0.9353727714748784', 'khmer: 0.9389221556886228', 'norsk: 0.8710505529225909', 'farsi: 0.9760581876957268', 'patwa: 0.9753297754506092']\n",
      "\n",
      "F1 micro-averaged: 0.9372315004635492\n",
      "\n",
      "F1 macro-averaged: 0.904556516291714\n"
     ]
    }
   ],
   "source": [
    "def evaluate(self: LanguageIdentifier, transcriptions: list, languages: list) -> None:  \n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "    modellen fungerer ved å beregne:\n",
    "    1) accuracy\n",
    "    2) precision, recall og F1 for hvert språk\n",
    "    3) micro- og macro-averaged F1.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = model.predict(transcriptions)\n",
    "    unique_langs = unique_languages(languages)\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(languages, prediction)\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n",
    "    \n",
    "    prec_rec = sklearn.metrics.precision_recall_fscore_support(languages, prediction)\n",
    "    \n",
    "    precision = [f\"{unique_langs[i]}: {n}\" for i,n in enumerate(prec_rec[0])] # list comprehension som legger til språk foran hver score -> ['kantonesisk: 0.9591753419065115', ...]\n",
    "    print(f\"Precision:\\n{precision}\\n\")\n",
    "    \n",
    "    recall = [f\"{unique_langs[i]}: {n}\" for i,n in enumerate(prec_rec[1])]\n",
    "    print(f\"Recall:\\n{recall}\\n\")\n",
    "    \n",
    "    f1score = sklearn.metrics.f1_score(languages, prediction, average=None)\n",
    "    f1 = [f\"{unique_langs[i]}: {n}\" for i,n in enumerate(f1score)]\n",
    "    print(f\"F1:\\n{f1}\\n\")\n",
    "    \n",
    "    f1_micro = sklearn.metrics.f1_score(languages, prediction, average='micro')\n",
    "    print(f\"F1 micro-averaged: {f1_micro}\\n\")\n",
    "    \n",
    "    f1_macro = sklearn.metrics.f1_score(languages, prediction, average='macro')\n",
    "    print(f\"F1 macro-averaged: {f1_macro}\")\n",
    "    \n",
    "LanguageIdentifier.evaluate = evaluate\n",
    " \n",
    "# Vi kan nå evaluere hvor godt modellen fungerer på testsett\n",
    "model.evaluate(test_data.IPA.values, test_data.språk.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse av modellen\n",
    "\n",
    "Hva har modellen egentlig lært? En stor fordel med logistisk regresjon er at modellene er relativt enkle å tolke: Hvis en vekt $w_i$ i modellen har stor positiv verdi betyr det at sannsynnlighet for outputklassen _øker_ sammen med trekket $x_i$.  Likeledes betyr en negativ verdi at sannsynlighet for outputklassen _reduseres_ med større verdier av $x_i$. Og jo større vektet er (positiv eller negativ), jo større er effekten. \n",
    "\n",
    "Vi kan inspisere modellen vår for å finne ut hvilke språklyder som har størst effekt på prediksjonene. I `scikit-learn` er modellvektene lagret i variabelen `coef_` (merk underscoren ved slutten). Siden modellen vår er multiklasse (med 20 unike språk) og inneholder $m \\approx 155$ trekk er vektene i `coef_` en matrise av dimensjon $(20,m)$. \n",
    "\n",
    "__Oppgave 1.6a__: Finn ut hvilket fonetisk symbol som bidrar mest til å øke sannsynnligheten for at et ord er klassifisert som norsk. Sjekk om det gir mening ved å telle hvor ofte symbolet forekommer i et norsk ord vs. ikke-norsk ord.\n",
    "\n",
    "__Oppgave 1.6b__: Finn ut hvilket fonetisk symbol som bidrar mest til å redusere sannsynnligheten for at et ord er klassifisert som norsk.\n",
    "\n",
    "Søk gjerne på nettet for å finnes ut hva disse fonetiske symbolene egentlig står for hvis du er interessert!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oppgave 1.6a:\n",
      "Symbolet som øker sannsynligheten mest for at et ord er klassifisert som norsk: ʋ\n",
      "\n",
      "Oppgave 1.6b:\n",
      "Symbolet som reduserer sannsynligheten mest for at et ord er klassifisert som norsk: ²\n"
     ]
    }
   ],
   "source": [
    "unique_symbols = model._extract_unique_symbols(transcriptions)\n",
    "\n",
    "norsk_coef = model.model.coef_[map_languages(languages, ['norsk'])].tolist()\n",
    "print(f\"Oppgave 1.6a:\\nSymbolet som øker sannsynligheten mest for at et ord er klassifisert som norsk: {unique_symbols[norsk_coef.index(max(norsk_coef))]}\")\n",
    "print()\n",
    "print(f\"Oppgave 1.6b:\\nSymbolet som reduserer sannsynligheten mest for at et ord er klassifisert som norsk: {unique_symbols[norsk_coef.index(min(norsk_coef))]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 2: sekvensmodellering\n",
    "\n",
    "Vi skal nå jobbe på en viktig anvendelse av sekvensmodeller, nemlig å gjenkjenne navngitte entiteter (_Named Entity Recognition_ eller NER på engelsk). For å gjøre det så enkelt som mulig vil vi bruke en _Hidden Markov Model_ som sekvensmodell. Hvert ord skal assosieres med en bestemte klasse, og vi skal ta i bruk såkalt BIO-annotering (også kalt IOB i boken til Jurafsky og Martin) for å spesifisere hvilke som ord hører til en navngitt entitet. \n",
    "\n",
    "_NB_: I praksis er ikke HMM den mest hensiktsmessige sekvensmodellen for å gjenkjenne navngitte enheter. Andre modeller slik som _transformers_ vil være bedre egnet til denne oppgaven, med disse modellene er betydelige mer kompliserte å trene. \n",
    "\n",
    "\n",
    "### Data \n",
    "Vi skal trene modellen med dataene i `norne_train.txt`. Filen inneholder tokeniserte setninger (en per linje) hvor de navngitte entitetene er markert med XML-tags, som f.eks:\n",
    "\n",
    "```xml\n",
    "De første 43 minuttene hadde <ORG>Rosenborg</ORG> all makt og \n",
    "tilnærmet full kontroll på <LOC>Fredrikstad Stadion</LOC> .\n",
    "```\n",
    "I eksempelet over har vi 2 navngitte enheter, _Rosenborg_ (en organisasjon) og _Fredrikstad Stadion_ (et sted).\n",
    "\n",
    "Vi har allerede implementert en funksjon `preprocess` som tar en tekst som input (som f.eks. setningene i trening- eller testsett) og ekstraherer lister over setninger og navngitte entiteter i disse setningene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['De',\n",
       "   'første',\n",
       "   '43',\n",
       "   'minuttene',\n",
       "   'hadde',\n",
       "   'Rosenborg',\n",
       "   'all',\n",
       "   'makt',\n",
       "   'og',\n",
       "   'tilnærmet',\n",
       "   'full',\n",
       "   'kontroll',\n",
       "   'på',\n",
       "   'Fredrikstad',\n",
       "   'Stadion',\n",
       "   '.']],\n",
       " [[(5, 6, 'ORG'), (13, 15, 'LOC')]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oblig1b_utils\n",
    "oblig1b_utils.preprocess(\"De første 43 minuttene hadde <ORG>Rosenborg</ORG> all makt og \" +\n",
    "                         \"tilnærmet full kontroll på <LOC>Fredrikstad Stadion</LOC> .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De navngitte entitetene er spesifisert som tupler $(i, j, tag)$ hvor $i$ er indeksen for starten av entiteten, $j$ er indeksen for slutten, og $tag$ er entitetstypen, som f.eks. ORG eller LOC. Indekstallene er på ordnivå:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassen\n",
    "\n",
    "Her er skjelettet for `NamedEntityRecogniser`-klassen  som skal implementeres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oblig1b_utils\n",
    "\n",
    "class NamedEntityRecogniser:\n",
    "    \"\"\"Gjenkjenning av navngitte enheter ved bruk av HMM\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Intialiserer alle variablene som er nødvendig for å representere og \n",
    "        estimere  sekvensmodellen (en Hidden Markov Model) som brukes til å \n",
    "        gjenkjenne de navngitte enhetene\"\"\"\n",
    "        \n",
    "        # alle labellene som forekommer i treningsettet\n",
    "        self.labels = set()\n",
    "\n",
    "        # alle token som forekommer i treningsettet\n",
    "        self.vocab = set()\n",
    "\n",
    "        # hvor mange ganger en label (f.eks. B-ORG) forekommer i treningsettet\n",
    "        self.label_counts = {}  \n",
    "\n",
    "        # hvor mange overgang fra label_1 til label2 forekommer i treningsettet\n",
    "        self.transition_counts = {}\n",
    "        \n",
    "        # hvor mange \"utslipp\" fra label til token forekommer i treningsettet\n",
    "        # (Merk at vi legger et spesielt symbol for ord som aldri forekommer\n",
    "        # i treningsettet, men kan forekomme i testsettet)\n",
    "        self.emission_counts = {(\"O\", \"<UNK>\"):1}\n",
    "                \n",
    "        # Sansynnlighet P(label_2 | label_1)\n",
    "        self.transition_probs = {}\n",
    "        \n",
    "        # Sansynnlighet P(token | label)\n",
    "        self.emission_probs = {}\n",
    "    \n",
    "    \n",
    "    def fit(self, tagged_text):\n",
    "        \"\"\"Estimerer tallene og sansynnlighetene for HMM, basert på (tokenisert)\n",
    "        tekst hvor navngitte enhetene er markert med XML tags (se norne.txt)\"\"\"\n",
    "        \n",
    "        # Ekstrahere setninger og navngitte enheter markert i hver setning\n",
    "        sentences, all_spans = oblig1b_utils.preprocess(tagged_text)\n",
    "                \n",
    "        for sentence, spans in zip(sentences, all_spans):\n",
    "            \n",
    "            # Ekstrahere labelsekvenser, med BIO marking\n",
    "            label_sequence = get_BIO_sequence(spans, len(sentence))\n",
    "            \n",
    "            # Oppdatere tallene \n",
    "            self._add_counts(sentence, label_sequence)\n",
    "            \n",
    "        # Beregne sansynnlighetene (transition og emission) ut fra tallene\n",
    "        self._fill_probs()\n",
    "        \n",
    "    def _add_counts(self, sentence, label_sequence):\n",
    "        \"\"\"Oppdaterer variablene self.vocab, self.labels, self.label_counts, \n",
    "        self.transition_counts og  self.emission_counts, basert på setningen og \n",
    "        sekvenslabellen assosiert med dem. \n",
    "        Merk at setningen og label_sequence har samme lengde.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _fill_probs(self, alpha_smoothing=1E-6):\n",
    "        \"\"\"Beregne sannsynlihetsfordelinger self.transition_probs og\n",
    "        self.emission_probs basert på tallene som er samlet inn i \n",
    "        self.label_counts, self.transition_counts og self.emission_counts.\n",
    "        \n",
    "        Når det gjeler self.emission_probs bør vi legge Laplace smoothing, med en\n",
    "        verdi for alpha som er alpha_smoothing.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "            \n",
    "    \n",
    "    def _beam_search(self, sentence):\n",
    "        \"\"\"Kjører beam-search på setningen (liste over tokens) og\n",
    "        returnerer to outputs: \n",
    "        1) en labelsekvens (som har samme lengde som setningen)\n",
    "        2) sansynnlighet for hele sekvensen \"\"\"\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "                \n",
    "    def label(self, text):\n",
    "        \"\"\"Gitt en tokenisert tekst, finner ut navngitte enheter og markere disse\n",
    "        med XML tags. \"\"\"\n",
    "        sentences, _ = oblig1b_utils.preprocess(text)\n",
    "        spans = []\n",
    "        for sentence in sentences:\n",
    "            sentence = [token if token in self.vocab else \"<UNK>\" for token in sentence]\n",
    "            label_sequence, _ = self._beam_search(sentence)\n",
    "            spans.append(oblig1b_utils.get_spans(label_sequence))\n",
    "        \n",
    "        return oblig1b_utils.postprocess(sentences, spans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO-markering\n",
    "\n",
    "\n",
    "For å trene en HMM må hvert ord kobles til en merkelapp (_label_). En vanlig måte å gjøre dette er å bruke en såkalt BIO-markering, hvor hvert ord markeres som:\n",
    "* 'O' (hvis ordet ikke tilhører en navngitt entitet)\n",
    "* 'B-X' (hvis ordet er det første ordet i en navngitt entitet av type 'X')\n",
    "* 'I-X' (hvis ordet tilhører en entitet av type 'X', men ikke er det første ordet)\n",
    "\n",
    "__Oppgave 2.1__: Implementer funksjonen _get_BIO_sequence_ som tar som input en liste med ``text spans'' og setningslengden og gir tilbake en rekke (av samme lengde som setningen) med BIO-markeringer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_BIO_sequence(spans: list, sentence_length: int) -> list:\n",
    "    \"\"\"Gitt en liste over \"spans\", representert som tuples (start, end, tag),\n",
    "    og en setningslengde, produserer en sekvens med BIO (også kalt IOB) labeller\n",
    "    for setningen. \n",
    "    Eksempel: hvis spans=[(1,3,'ORG')] og sentence_length=6 bør resultatet være\n",
    "    ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']\"\"\"\n",
    "    \n",
    "    result = ['O'] * sentence_length\n",
    "    \n",
    "    for span in spans:\n",
    "        entity = span[2]\n",
    "        current = [f\"I-{entity}\"] * (span[1] - span[0])\n",
    "        current[0] = f\"B-{entity}\"\n",
    "        \n",
    "        for i, l in enumerate(current):\n",
    "            result[i + span[0]] = l\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Telling\n",
    "\n",
    "Som vi så i forelesningen er Hidden Markov Models definert med en vokabular (som tilsvarer ``observasjonene''), et sett mulig merkelapp (de skjulte tilstandene), og to sannsynlighetsfordelinger:\n",
    "* Den første fordelingen er kalt transisjonsmodell og definert som $P(label_t | label_{t-1})$. Transisjonsmodellen forteller oss hvor sannsynlig det er at $label_{t-1}$ (assosiert med ord $w_{t-1}$) følges av $label_t$ (assosiert med ord $w_t$). \n",
    "* Den andre fordelingen er emisjonsmodellen, definert som $P(w_t | label_t)$. Emisjonsmodellen forteller oss hvor sannsynlig det er å observere ordet $w_t$ hvis merkelappen for dette ordet er $label_t$.\n",
    "\n",
    "For å estimere disse to sannsynlighetsfordelinger må vi telle:\n",
    "* Alle ordene som forekommer i treningssettet\n",
    "* Alle BIO-labels som forekommer i treningssettet\n",
    "* Antall ganger hver BIO-label forekommer i treningssettet\n",
    "* Antall ganger to BIO-labels følger hverandre i treningssettet\n",
    "* Antall ganger et ord er observert med en BIO-label i treningssettet\n",
    "\n",
    "__Oppgave 2.2__: Implementer metoden `_add_counts` som oppdaterer variablene som inneholder disse tallene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_counts(self: NamedEntityRecogniser, sentence: list, label_sequence: list) -> None:\n",
    "    \"\"\"Oppdaterer variablene self.vocab, self.labels, self.label_counts, \n",
    "    self.transition_counts og  self.emission_counts, basert på setningen og \n",
    "    sekvenslabellene assosiert med dem. \n",
    "    Merk at setningen og label_sequence må ha samme lengde.\"\"\"\n",
    "    \n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    # print(f\"Label sequence: {label_sequence}\")\n",
    "    \n",
    "    prev_label = None\n",
    "    for token, label in zip(sentence, label_sequence):        \n",
    "        # self.vocab (alle ordene som forekommer)\n",
    "        if token not in self.vocab:\n",
    "            self.vocab.add(token)\n",
    "        \n",
    "        # self.labels (alle bio-labels som forekommer)\n",
    "        if label not in self.labels:\n",
    "            self.labels.add(label)\n",
    "        \n",
    "        # self.label_counts (antall ganger hver bio-label forekommer)\n",
    "        if not self.label_counts.get(label):\n",
    "            self.label_counts[label] = 0\n",
    "        self.label_counts[label] += 1\n",
    "        \n",
    "        # self.transition_counts (antall ganger to bio-labels følger hverandre)\n",
    "        if prev_label:\n",
    "            trans = (prev_label, label)\n",
    "            if not self.transition_counts.get(trans):\n",
    "                self.transition_counts[trans] = 0\n",
    "            self.transition_counts[trans] += 1\n",
    "        prev_label = label\n",
    "        \n",
    "        # self.emission_counts (antall ganger et ord er observert med en bio-label)\n",
    "        emission = (label, token)\n",
    "        if not self.emission_counts.get(emission):\n",
    "            self.emission_counts[emission] = 0\n",
    "        self.emission_counts[emission] += 1\n",
    "    \n",
    "NamedEntityRecogniser._add_counts = _add_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sannsynligheterfordelinger\n",
    "\n",
    "Med hjelp av disse tallene kan vi nå estimere transisjonsmodellen og emisjonsmodellen. For emisjonsmodellen bør dere legge til _Laplace smoothing_ for å gjøre modellen mer robust, da treningssettet er relativt lite. La oss si at $C(label)$ er antall ganger BIO-merkelappen $label$ ble observert, og $C(label, token)$ antall ganger ordet $token$ ble observert sammen med $label$.  Ved hjelp av Laplace smoothing definerer vi sannsynligheten $P(token | label)$ slik:\n",
    "\n",
    "$$\n",
    "P(token | label) = \\frac{C(label, token) + \\alpha}{C(label) + \\alpha V}\n",
    "$$\n",
    "\n",
    "hvor $V$ er størrelsen på vokabularet. \n",
    "\n",
    "__Oppgave 2.3__: Implementer metoden `_fill_probs` som beregner transisjonsmodellen og emisjonsmodellen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_probs(self: NamedEntityRecogniser, alpha_smoothing=1E-6):\n",
    "    \"\"\"Beregne sannsynlihetsfordelinger self.transition_probs og\n",
    "    self.emission_probs basert på tallene som er samlet inn i \n",
    "    self.label_counts, self.transition_counts og self.emission_counts.\n",
    "    \n",
    "    Når det gjeler self.emission_probs bør vi legge Laplace smoothing, med en\n",
    "    verdi for alpha som er alpha_smoothing.\"\"\"\n",
    "    \n",
    "    # emission_probs:\n",
    "    for key, count in self.emission_counts.items():\n",
    "        p = (count + alpha_smoothing) / (self.label_counts[key[0]] + (alpha_smoothing * len(self.vocab))) \n",
    "        self.emission_probs[key] = p\n",
    "    \n",
    "    # transition_probs:\n",
    "    for key, count in self.transition_counts.items():\n",
    "        p = count / self.label_counts[key[0]] # C(label1,label2) / C(label1)\n",
    "        self.transition_probs[key] = p\n",
    "    \n",
    "NamedEntityRecogniser._fill_probs = _fill_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og vi kan nå trene modellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the model\n",
    "with open(\"norne_train.txt\") as fd:\n",
    "    model = NamedEntityRecogniser()\n",
    "    training_texts = fd.read()\n",
    "    model.fit(training_texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dekoding med beam search\n",
    "\n",
    "Til slutt skal vi implementere metoden `_beam_search` som skal finne den mest sannsynlige label-sekvensen for en setning ved hjelp av beam-search-algoritmen. \n",
    "\n",
    "Vi har sett hvordan beam search fungerer i forelesningen. Kort fortalt består et _beam_ av en mengde _hypoteser_, hvor en hypotese representerer her en mulig sekvens av BIO-labeller for setningen. Vi bygger opp disse hypotesene ord etter ord, inntil alle ordene er behandlet. I beam-search begrenser vi antall hypoteser som kan lagres etter hvert steg (=_beam width_) for å unngå en kombinatorisk eksplosjon.\n",
    "\n",
    "__Oppgave 2.4__: Implementer metoden `_beam_search`. For å gjøre det litt lettere er metoden allerede delvis implementert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _beam_search(self: NamedEntityRecogniser, sentence: list, beam_width=3):\n",
    "    \"\"\"Kjører beam search på setningen (liste over tokens), og\n",
    "    returnerer to outputs: \n",
    "    1) en labelsekvens (som har samme lengde som setningen)\n",
    "    2) sansynnlighet for hele sekvensen \"\"\"\n",
    "\n",
    "    # Vi starter med en beam som består av én tom hypotese\n",
    "    # Hver hypotese i beam består av to elementer:\n",
    "    # -'labels' er en liste over BIO-labels (en label per ord i setningen)\n",
    "    # -'prob' er sannsynligheten for denne labelsekvensen\n",
    "    beam = [{\"labels\":[], \"prob\":1.0}]\n",
    "    \n",
    "    for token in sentence:\n",
    "        new_hypotheses = []\n",
    "\n",
    "        for hypothesis in beam:\n",
    "            if hypothesis[\"labels\"]:\n",
    "                prev_label = hypothesis[\"labels\"][-1]\n",
    "            else:\n",
    "                prev_label = None\n",
    "\n",
    "            for label in self.labels:\n",
    "                # emission prob av current token gitt current label. hvis den ikke finnes, bruk UNK emission prob\n",
    "                emission_prob = self.emission_probs.get(\n",
    "                    (label, token),\n",
    "                    self.emission_probs.get((label, '<UNK>'), 0)\n",
    "                )\n",
    "\n",
    "                transition_prob = self.transition_probs.get(\n",
    "                    (prev_label, label),\n",
    "                    1.0 if prev_label is None else 0\n",
    "                )\n",
    "                \n",
    "                new_prob = hypothesis[\"prob\"] * transition_prob * emission_prob\n",
    "                \n",
    "                new_hypothesis = {\"labels\": hypothesis[\"labels\"][:] + [label], \"prob\": new_prob}\n",
    "                new_hypotheses.append(new_hypothesis)\n",
    "\n",
    "        # behold beam_width beste hypoteser\n",
    "        beam = sorted(new_hypotheses, key=lambda x: x[\"prob\"], reverse=True)[:beam_width]  \n",
    "        \n",
    "    # Vi velger hypotesen med høyest sannsynlighet\n",
    "    best_hypothesis = sorted(beam, key=lambda x : x[\"prob\"])[-1]\n",
    "\n",
    "    # Og returnerer labelsekvensen og dens sannsynlighet\n",
    "    return best_hypothesis[\"labels\"], best_hypothesis[\"prob\"]\n",
    "\n",
    "NamedEntityRecogniser._beam_search = _beam_search            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når dere har implementert modellen ferdig kan dere teste ut hvordan den fungerer ved å kalle metoden `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PER>Kjell Magne Bondevik</PER> var statsminister i <GPE>Norge</GPE> .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the model to a sample sentence\n",
    "model.label(\"Kjell Magne Bondevik var statsminister i Norge .\")\n",
    "# Forventet svar: '<PER>Kjell Magne Bondevik</PER> var statsminister i <GPE>Norge</GPE> .'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valgfritt spørsmål (for de modigste)\n",
    " \n",
    "Det er ofte en dårlig idé å gange mange små sannsynligheter, da vi kan havne i numerisk _underflow_. En vanlig løsning er å benytte log-sannsynligheter som kan summeres i stedet for å multipliseres, slik som forklart [her](http://www.cs.columbia.edu/~mcollins/cs4705-fall2018/notes-on-logs.pdf).\n",
    "\n",
    "__Oppgave 2.5__: Prøv å implementere beam search algoritmen med log-sannsynligheter.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3529d1d89cb4c8d13e402e4117b8dc865480f261d07f0716e8c60a591b54d3ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
