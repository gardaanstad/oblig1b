{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN2110 obligatorisk innlevering 1b\n",
    "\n",
    "Oppgaven har to deler, logistisk regresjon for å klassifisere språk basert på IPA lydskrift, og Named Entity Recognition med HMM. Det er en god idé å lese gjennom hele oppgavesettet før du setter i gang. \n",
    "\n",
    "Dersom du har spørsmål så kan du:\n",
    "\n",
    "* gå på gruppetime,\n",
    "* spørre på Discourse\n",
    "* eller sende epost til in2110-hjelp@ifi.uio.no dersom alternativene over av en eller annen grunn ikke passer for spørsmålet ditt.\n",
    "\n",
    "### Oppsett\n",
    "Når du har klonet dette github-repoet som denne notebooken ligger i, har du tilgang til datene og hjelpefilene som ligger i denne mappa. Hvis du ønsker å kopiere denne mappa, \"1b\", over til et annet sted, så skulle det gå bra. Bare pass på at du følger med på om det er oppdateringer her i repoet som gir ut obligen. Når du har aktivert in2110-miljøet med conda, så har du tilgang til pakkene som trengs for å kjøre denne notebooken. Vi har forberedt en notebook med all prekoden, der du også kan fylle ut din kode og kjøre prosessene.\n",
    "\n",
    "### Innlevering\n",
    "\n",
    "Innleveringen skal helst bestå av denne Jupyter notebook fylt ut med både kode og tilhørende forklaringer. Vi understreker at innlevering av koden alene __ikke er nok__ for å bestå oppgaven -- vi forventer at notebooken også skal inneholde _beskrivelser_ (på norsk eller engelsk) av hva dere har gjort og _begrunnelser_ for valgene dere har tatt underveis. Bruk helst hele setninger, og matematiske formler om nødvendig. Evalueringstallene bør presenteres i tabeller. Det å  forklare med egne ord (samt begreper vi har gått gjennom på forelesningene) hva dere har implementert og reflektere over hvorvidt løsningen dere har lagt  besvarer oppgaven er en viktig del av læringsprosessen -- ta det på alvor! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 1: Logistisk regresjon\n",
    "\n",
    "\n",
    "I den første delen av innleveringen skal vi bruke logistisk regresjon til å utvikle en enkel _språkidentifikator_, dvs. et lite system som skal predikere hvilket språk et ord hører til. Mer spesifikk skal systemet ta ordets _fonetiske transkripsjon_ som input og returnere _navnet på språket_ som ordet mest sannsynlig tilhører.  Systemet skal for eksempel kunne ta transkripsjonen [bʊndɛsvɛɾfaszʊŋ] som input og returnere ``tysk''. \n",
    "\n",
    "## Data\n",
    "\n",
    "For å trene modellen (dvs. finne ut verdier for vektene og skjæringspunktene basert på data) skal vi ta i bruk eksisterende lister over ord med deres fonetiske transkripsjon i såkalt _IPA_-format (IPA står for _[International Phonetic Alphabet](https://upload.wikimedia.org/wikipedia/commons/8/8e/IPA_chart_2018.pdf)_).  Dere trenger ikke å kunne lese eller skrive slike fonetiske transkripsjoner i denne oppgaven. Det viktigste er å forstå at disse transkripsjonene beskriver språklydene som utgjør ordet, samt andre egenskaper slik som lengde, tone, trykk og intonasjon. Fonetiske transkripsjoner forteller oss hvordan et ord bør uttales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cached file from ./langid_data.csv\n",
      "Treningsett: 689238 eksempler, testsett: 76583 eksempler\n"
     ]
    }
   ],
   "source": [
    "import oblig1b_utils \n",
    "train_data, test_data = oblig1b_utils.extract_wordlist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data vi skal bruke er lagt i to `DataFrame` tabeller: et treningsett med 90 % av ordene og et testsett med de resterende 10 %. Ordene fra de forskjellige språkene er blandet i disse to tabellene. `DataFrame` er en datastruktur fra Python-biblioteket [`pandas`](https://pandas.pydata.org) og representerer en slags tabell med kolonner og rader. Biblioteket `pandas` gjør det lett å visualisere og manipulere slike tabeller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistikk over språkene i treningsett:\n",
      "språk\n",
      "tysk            45064\n",
      "engelsk         45047\n",
      "rumensk         45010\n",
      "islandsk        45008\n",
      "finsk           45002\n",
      "fransk          45000\n",
      "japansk         45000\n",
      "spansk          45000\n",
      "arabisk         44960\n",
      "vietnamesisk    44959\n",
      "koreansk        44931\n",
      "kantonesisk     44919\n",
      "swahilisk       43459\n",
      "mandarin        40345\n",
      "malayisk        25454\n",
      "svensk          19009\n",
      "norsk            9133\n",
      "farsi            7289\n",
      "khmer            2957\n",
      "patwa            1692\n",
      "Name: count, dtype: int64\n",
      "Første 30 ord:\n",
      "                                   ord  \\\n",
      "619361                        فللمعارف   \n",
      "239761                     atudanganye   \n",
      "69819              đẹp như trong tranh   \n",
      "386616                            sota   \n",
      "282192                            서뻑서뻑   \n",
      "166501                    transmitting   \n",
      "24063                       وبالبواقيل   \n",
      "486787                     empesterait   \n",
      "744700               nhí nha nhí nhoẻn   \n",
      "383563                       急性散在性脳脊髄炎   \n",
      "180721                         asarías   \n",
      "582323                             鳥龍茶   \n",
      "667561                          dandia   \n",
      "476485                          topist   \n",
      "695906                         sumbing   \n",
      "513419                            hest   \n",
      "452619                             toe   \n",
      "211833                               湃   \n",
      "743224                        mirihani   \n",
      "314558                     Lachanfalle   \n",
      "38458                         áætlaður   \n",
      "69670   khéo con mắt, vụng hai bàn tay   \n",
      "154691                     untraceable   \n",
      "360393                 kilpapyöräilijä   \n",
      "541415                   gúmmíræmurnar   \n",
      "496164                     deselection   \n",
      "264868                         wrestle   \n",
      "63227                              生積仔   \n",
      "439705                         蚊とりせんこう   \n",
      "723297                               䂾   \n",
      "\n",
      "                                                    IPA         språk  \n",
      "619361                                    falilmaʕaːrif       arabisk  \n",
      "239761                                       atuɗaᵑgaɲe     swahilisk  \n",
      "69819                        dɛp˨ˀ˩ʔ ɲɯ˧˥ ʈɔŋ͡m˧˥ ʈan˧˥  vietnamesisk  \n",
      "386616                                          ²sˈuːta        svensk  \n",
      "282192                              sʰʌ̹p͈ʌ̹ks͈ʌ̹p͈ʌ̹k̚      koreansk  \n",
      "166501                                      tɹænsmˈɪtɪŋ       engelsk  \n",
      "24063                                  wabiaːlbaʊaːqiːl       arabisk  \n",
      "486787                                        ɑ̃pɛstəʁɛ        fransk  \n",
      "744700                           ɲi˩˧ ɲa˧˥ ɲi˩˧ ɲwen˧˩˨  vietnamesisk  \n",
      "383563                     kjɯɯseisaɴzaiseinoɯsekizɯieɴ       japansk  \n",
      "180721                                         asaˈɾias        spansk  \n",
      "582323                                         ɯːɾoɴtɕa       japansk  \n",
      "667561                                           ɗaⁿɗia     swahilisk  \n",
      "476485                                           topist       rumensk  \n",
      "695906                                           sumbiŋ      malayisk  \n",
      "513419                                             hɛst         norsk  \n",
      "452619                                            twe˧˥  vietnamesisk  \n",
      "211833                                            pa:i˧   kantonesisk  \n",
      "743224                                         miɾihani     swahilisk  \n",
      "314558                                     ˈlaxʔanˌfalə          tysk  \n",
      "38458                                      auːaihtlaðʏr      islandsk  \n",
      "69670   xeo˩˧ kɔŋ͡m˧˥ măk˦˥ juŋ͡m˨ˀ˩ʔ haj˧˥ baŋ˦˨ tăj˧˥  vietnamesisk  \n",
      "154691                                   ʌntɹˈe‍ɪsəbə‍l       engelsk  \n",
      "360393                               ˈkilpɑˌpyøræiˌlijæ         finsk  \n",
      "541415                                   kumiraiːmʏtnar      islandsk  \n",
      "496164                                    dˌiːsɪlˈɛkʃən       engelsk  \n",
      "264868                                          ɹˈɛsə‍l       engelsk  \n",
      "63227                                sa:ŋ˥ tsɪk˥ tsɐi˧˥   kantonesisk  \n",
      "439705                                     katoɾiseɴkoɯ       japansk  \n",
      "723297                                            lei˨˩   kantonesisk  \n"
     ]
    }
   ],
   "source": [
    "print(\"Statistikk over språkene i treningsett:\")\n",
    "print(train_data.språk.value_counts())\n",
    "print(\"Første 30 ord:\")\n",
    "print(train_data[:30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassen\n",
    "\n",
    "Her er skjelettet for `LanguageIdentifier`-klassen  som skal implementeres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "class LanguageIdentifier:\n",
    "    \"\"\"Logistisk regresjonsmodell som tar IPA transkripsjoner av ord som input, \n",
    "    og predikerer hvilke språkene disse ordene hører til.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialiser modellen\"\"\"      \n",
    "        # selve regresjonsmodellen (som brukes all CPU-er på maskinen for trening)\n",
    "        self.model = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", multi_class='ovr')\n",
    "    \n",
    "    def train(self, transcriptions, languages):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "        den logistisk regresjonsmodellen. De to rekkene må ha samme lendgen\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "        for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "        \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "        symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _extract_feats(self, transcriptions):\n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "        hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def evaluate(self, transcriptions, languages):  \n",
    "        \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "        modellen fungerer ved å beregne:\n",
    "        1) accuracy\n",
    "        2) precision, recall og F1 for hvert språk\n",
    "        3) micro- og macro-averaged F1.\n",
    "        \"\"\"\n",
    "        \n",
    "        # See API fra sklearn.metrics for å finne ut hvordan dette kan gjøres! \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening \n",
    "Vi skal benytte oss av en logistisk regresjonsmodell, mer spesifikk klassen [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) fra `scikit-learn`. Men for å kunne bruke modellen må vi naturligvis først estimere parametrene basert på treningsdata. \n",
    " Hva slags trekk (_features_) skal vi bruke i modellen vår? I denne oppgaven skal vi gjøre det enkelt for oss selv, og kun ta i betrakning forekomst av bestemte IPA-symboler som identifiserer ordlyder i den fonetiske transkripsjonen av ordet. _NB_: hvis du kan litt fonetikk fra før vil dere kanskje stusse på denne overforenklingen, da IPA-symboler brukes til å kode en god del andre egenskaper knyttet til talelyder slik som lengde, tone, trykk og intonasjon. Men i denne oppgaven skal vi gå den enkle veien og bruke alle symbolene i disse transkripsjonene uten å skille mellom ulike typer.\n",
    "\n",
    "Trekkene vil ha binære verdier (1 hvis transkripsjonen inneholder symbolet og 0 ellers) og kan sees som en slags ``bag-of-sounds'', siden de vil fortelle oss hvilke ordlyder som forekommer i ordet, men ikke i hvilken rekkefølge.\n",
    "\n",
    "__Opgave 1.1:__ Det første skrittet er å lage en liste over alle IPA-symboler som finnes i treningsettet. Metoden `_extract_unique_symbols` skal ta de fonetiske transkripsjonene fra treningssettet som input, og returnere en liste med alle fonetiske symboler (altså tegn) som finnes i disse transkripsjonene og forekommer minst 10 ganger. Implementer denne metoden. Antall symboler kan variere litt avhengig av den tilfeldige inndelingen mellom treningsettet og testsettet, men bør ligge på rundt 155 unike symboler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_unique_symbols(self, transcriptions, min_nb_occurrences=10):\n",
    "    \"\"\"Gitt en rekke med IPA fonetiske transkripsjoner, ektraher en liste med alle IPA \n",
    "    symboler som finnes i transkripsjonene og forekommer minst min_nb_occurrences.\"\"\"\n",
    "\n",
    "    symbols = {}\n",
    "    for word in transcriptions:\n",
    "        for symbol in word:\n",
    "            if symbol not in symbols:\n",
    "                symbols[symbol] = 0\n",
    "            symbols[symbol] += 1\n",
    "    \n",
    "    result = [symbol for symbol, n in symbols.items() if n > min_nb_occurrences]\n",
    "    return result\n",
    "    \n",
    "# her kobler vi metoden vi har implementert til klassen\n",
    "LanguageIdentifier._extract_unique_symbols = _extract_unique_symbols \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Oppgave 1.2__: Deretter må vi implementere metoden `_extract_feats` som tar en liste fonetiske transkripsjoner og returnerer en matrise $X$ hvor hver rad tilsvarer en transkripsjon og hver kolonne representerer et bestemt trekk. La oss si vi har $m$ unike fonetiske symboler (ekstrahert med metoden ovenfor), og får en liste med $n$ fonetiske transkripsjoner $T = \\{t_i \\text{ hvor } 0 < i < n\\}$. Metoden `_extract_feats(transcriptions)` må returnere en matrise $X$ av dimensjon $(n,m)$, hvor hver matrisecelle $X_{ij}$ er definert slik: \n",
    "\n",
    "$$\n",
    "X_{ij}  =  \\begin{cases} 1 \\text{  hvis symbolet } j \\text{ forekommer i transkripsjonen } t_i \\\\\n",
    "0 \\text{  ellers} \\end{cases} \n",
    "$$\n",
    "\n",
    "Tips: den enkleste fremgangsmåten kan være å starte med å lage en tom matrise slik som `X = np.zeros(n,m)` og deretter endre cellene hvor `X[i,j]` skal ha 1 som verdi i stedet for 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689238\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _extract_feats(self, transcriptions):\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner, ekstraher en matrise av størrelse |T|x|F|,\n",
    "    hvor |T| er antall transkripsjoner, og |F| er antall features brukt i modellen.\"\"\"\n",
    "    \n",
    "    unique_symbols = _extract_unique_symbols(self, transcriptions)\n",
    "    m = len(unique_symbols)\n",
    "    n = len(transcriptions)\n",
    "    \n",
    "    print(n)\n",
    "    print(m)\n",
    "    \n",
    "    X = np.zeros((n, m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if unique_symbols[j] in transcriptions[i]:\n",
    "                X[i][j] = 1\n",
    "\n",
    "LanguageIdentifier._extract_feats = _extract_feats\n",
    "model = LanguageIdentifier()\n",
    "transcriptions = train_data.IPA.values\n",
    "model._extract_feats(transcriptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oppgave 1.3__: Vi er nå klare til for å implementere funksjonen `train`. Metoden tar to lister som input, en liste fonetiske transkripsjoner og en liste med språknavn (de to listene må ha samme lengde). Metoden skal trene den logistiske regresjonsmodellen `self.model` ved å kalle `fit(X, y)`, hvor `X` er en matrise med alle trekk ekstrahert med metoden `_extract_feats`, og `y` er outputklassene. \n",
    "\n",
    "Merk at `scikit-learn` krever at outputklassene `y` må være en liste med heltall (og ikke strenger). Det betyr at dere må lage en mapping mellom språknavn og heltall (f.eks. ved å si at \"norsk\" er 0, \"arabisk\" er 1, \"finsk\" er 2, osv.). Når dere har både matrisen `X` og output `y` er det bare å kalle metoden `fit(X, y)` for å trene modellen. Trening kan ta noen minutter avhengig av maskinen deres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, transcriptions, languages):\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, tren\n",
    "    den logistisk regresjonsmodellen. De to rekkene må ha samme lendgen\"\"\"\n",
    "        \n",
    "    # Implementer metoden her!\n",
    "\n",
    "LanguageIdentifier.train = train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi er nå klare til å trene modellen (kan ta noen minutter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageIdentifier()\n",
    "transcriptions = train_data.IPA.values\n",
    "languages = train_data.språk.values\n",
    "model.train(transcriptions, languages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prediksjon og evaluering\n",
    "\n",
    "Når modellen er trent kan vi anvende den på nye fonetiske transkripsjoner. \n",
    "\n",
    "__Oppgave 1.4__: Implementer metoden `predict`. Metoden tar som input en liste fonetiske transkripsjoner og predikerer det mest sannsynlige språket for hver transkripsjon. Listen som returneres må ha samme lengde som inputlisten. Husk at `scikit-learn` opererer med outputklasser representert som heltall, så dere må forvandle disse tallene tilbake til språknavnene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, transcriptions):\n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner, finn ut det mest sansynnlige språket\n",
    "    for hver transkripsjon. Rekken som returneres må ha samme lengden som rekken i input\"\"\"\n",
    "        \n",
    "    # Implementer metoden her!\n",
    "\n",
    "LanguageIdentifier.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deretter kan dere se hvordan modellen fungerer i praksis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi kan nå teste modellen på nye data\n",
    "predicted_langs = model.predict([\"konstituˈθjon\", \"ɡrʉnlɔʋ\", \"stjourtnar̥skrauːɪn\", \"perusˌtuslɑki\"])\n",
    "print(\"Mest sansynnlige språk for ordene:\", predicted_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Svarene bør være spansk, norsk, islandsk og finsk)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oppgave 1.5__: Til slutt kan vi gjennomføre en grundigere evaluering av modellen basert på testsettet. Implementer metoden `evaluate`. Metoden skal beregne og skrive ut de følgende evalueringsmålene:\n",
    "* accuracy (den bør ligge rund 93 % hvis dere har gjort alt riktig.)\n",
    "* precision, recall og $F_1$ for hvert språk\n",
    "* micro- og macro-averaged F1.    \n",
    "    \n",
    "For å beregne disse stallene kan dere bruke metodene fra [`sklearn.metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, transcriptions, languages):  \n",
    "    \"\"\"Gitt en rekke med IPA transkripsjoner og en rekke med språknavn, evaluer hvor godt\n",
    "    modellen fungerer ved å beregne:\n",
    "    1) accuracy\n",
    "    2) precision, recall og F1 for hvert språk\n",
    "    3) micro- og macro-averaged F1.\n",
    "    \"\"\"\n",
    "     # Implementer metoden her!\n",
    "\n",
    "LanguageIdentifier.evaluate = evaluate\n",
    " \n",
    "# Vi kan nå evaluere hvor godt modellen fungerer på testsett\n",
    "model.evaluate(test_data.IPA.values, test_data.språk.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse av modellen\n",
    "\n",
    "Hva har modellen egentlig lært? En stor fordel med logistisk regresjon er at modellene er relativt enkle å tolke: Hvis en vekt $w_i$ i modellen har stor positiv verdi betyr det at sannsynnlighet for outputklassen _øker_ sammen med trekket $x_i$.  Likeledes betyr en negativ verdi at sannsynlighet for outputklassen _reduseres_ med større verdier av $x_i$. Og jo større vektet er (positiv eller negativ), jo større er effekten. \n",
    "\n",
    "Vi kan inspisere modellen vår for å finne ut hvilke språklyder som har størst effekt på prediksjonene. I `scikit-learn` er modellvektene lagret i variabelen `coef_` (merk underscoren ved slutten). Siden modellen vår er multiklasse (med 20 unike språk) og inneholder $m \\approx 155$ trekk er vektene i `coef_` en matrise av dimensjon $(20,m)$. \n",
    "\n",
    "__Oppgave 1.6a__: Finn ut hvilket fonetisk symbol som bidrar mest til å øke sannsynnligheten for at et ord er klassifisert som norsk. Sjekk om det gir mening ved å telle hvor ofte symbolet forekommer i et norsk ord vs. ikke-norsk ord.\n",
    "\n",
    "__Oppgave 1.6b__: Finn ut hvilket fonetisk symbol som bidrar mest til å redusere sannsynnligheten for at et ord er klassifisert som norsk.\n",
    "\n",
    "Søk gjerne på nettet for å finnes ut hva disse fonetiske symbolene egentlig står for hvis du er interessert!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 2: sekvensmodellering\n",
    "\n",
    "Vi skal nå jobbe på en viktig anvendelse av sekvensmodeller, nemlig å gjenkjenne navngitte entiteter (_Named Entity Recognition_ eller NER på engelsk). For å gjøre det så enkelt som mulig vil vi bruke en _Hidden Markov Model_ som sekvensmodell. Hvert ord skal assosieres med en bestemte klasse, og vi skal ta i bruk såkalt BIO-annotering (også kalt IOB i boken til Jurafsky og Martin) for å spesifisere hvilke som ord hører til en navngitt entitet. \n",
    "\n",
    "_NB_: I praksis er ikke HMM den mest hensiktsmessige sekvensmodellen for å gjenkjenne navngitte enheter. Andre modeller slik som _transformers_ vil være bedre egnet til denne oppgaven, med disse modellene er betydelige mer kompliserte å trene. \n",
    "\n",
    "\n",
    "### Data \n",
    "Vi skal trene modellen med dataene i `norne_train.txt`. Filen inneholder tokeniserte setninger (en per linje) hvor de navngitte entitetene er markert med XML-tags, som f.eks:\n",
    "\n",
    "```xml\n",
    "De første 43 minuttene hadde <ORG>Rosenborg</ORG> all makt og \n",
    "tilnærmet full kontroll på <LOC>Fredrikstad Stadion</LOC> .\n",
    "```\n",
    "I eksempelet over har vi 2 navngitte enheter, _Rosenborg_ (en organisasjon) og _Fredrikstad Stadion_ (et sted).\n",
    "\n",
    "Vi har allerede implementert en funksjon `preprocess` som tar en tekst som input (som f.eks. setningene i trening- eller testsett) og ekstraherer lister over setninger og navngitte entiteter i disse setningene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oblig1b_utils\n",
    "oblig1b_utils.preprocess(\"De første 43 minuttene hadde <ORG>Rosenborg</ORG> all makt og \" +\n",
    "                         \"tilnærmet full kontroll på <LOC>Fredrikstad Stadion</LOC> .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De navngitte entitetene er spesifisert som tupler $(i, j, tag)$ hvor $i$ er indeksen for starten av entiteten, $j$ er indeksen for slutten, og $tag$ er entitetstypen, som f.eks. ORG eller LOC. Indekstallene er på ordnivå:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassen\n",
    "\n",
    "Her er skjelettet for `NamedEntityRecogniser`-klassen  som skal implementeres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oblig1b_utils\n",
    "\n",
    "class NamedEntityRecogniser:\n",
    "    \"\"\"Gjenkjenning av navngitte enheter ved bruk av HMM\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Intialiserer alle variablene som er nødvendig for å representere og \n",
    "        estimere  sekvensmodellen (en Hidden Markov Model) som brukes til å \n",
    "        gjenkjenne de navngitte enhetene\"\"\"\n",
    "        \n",
    "        # alle labellene som forekommer i treningsettet\n",
    "        self.labels = set()\n",
    "\n",
    "        # alle token som forekommer i treningsettet\n",
    "        self.vocab = set()\n",
    "\n",
    "        # hvor mange ganger en label (f.eks. B-ORG) forekommer i treningsettet\n",
    "        self.label_counts = {}  \n",
    "\n",
    "        # hvor mange overgang fra label_1 til label2 forekommer i treningsettet\n",
    "        self.transition_counts = {}\n",
    "        \n",
    "        # hvor mange \"utslipp\" fra label til token forekommer i treningsettet\n",
    "        # (Merk at vi legger et spesielt symbol for ord som aldri forekommer\n",
    "        # i treningsettet, men kan forekomme i testsettet)\n",
    "        self.emission_counts = {(\"O\", \"<UNK>\"):1}\n",
    "                \n",
    "        # Sansynnlighet P(label_2 | label_1)\n",
    "        self.transition_probs = {}\n",
    "        \n",
    "        # Sansynnlighet P(token | label)\n",
    "        self.emission_probs = {}\n",
    "    \n",
    "    \n",
    "    def fit(self, tagged_text):\n",
    "        \"\"\"Estimerer tallene og sansynnlighetene for HMM, basert på (tokenisert)\n",
    "        tekst hvor navngitte enhetene er markert med XML tags (se norne.txt)\"\"\"\n",
    "        \n",
    "        # Ekstrahere setninger og navngitte enheter markert i hver setning\n",
    "        sentences, all_spans = oblig1b_utils.preprocess(tagged_text)\n",
    "                \n",
    "        for sentence, spans in zip(sentences, all_spans):\n",
    "     \n",
    "            # Ekstrahere labelsekvenser, med BIO marking\n",
    "            label_sequence = get_BIO_sequence(spans, len(sentence))\n",
    "                                              \n",
    "            # Oppdatere tallene \n",
    "            self._add_counts(sentence, label_sequence)\n",
    "            \n",
    "        # Beregne sansynnlighetene (transition og emission) ut fra tallene\n",
    "        self._fill_probs()\n",
    "                   \n",
    "        \n",
    "    def _add_counts(self, sentence, label_sequence):\n",
    "        \"\"\"Oppdaterer variablene self.vocab, self.labels, self.label_counts, \n",
    "        self.transition_counts og  self.emission_counts, basert på setningen og \n",
    "        sekvenslabellen assosiert med dem. \n",
    "        Merk at setningen og label_sequence har samme lengde.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _fill_probs(self, alpha_smoothing=1E-6):\n",
    "        \"\"\"Beregne sannsynlihetsfordelinger self.transition_probs og\n",
    "        self.emission_probs basert på tallene som er samlet inn i \n",
    "        self.label_counts, self.transition_counts og self.emission_counts.\n",
    "        \n",
    "        Når det gjeler self.emission_probs bør vi legge Laplace smoothing, med en\n",
    "        verdi for alpha som er alpha_smoothing.\"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "            \n",
    "    \n",
    "    def _beam_search(self, sentence):\n",
    "        \"\"\"Kjører beam-search på setningen (liste over tokens) og\n",
    "        returnerer to outputs: \n",
    "        1) en labelsekvens (som har samme lengde som setningen)\n",
    "        2) sansynnlighet for hele sekvensen \"\"\"\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "                \n",
    "    def label(self, text):\n",
    "        \"\"\"Gitt en tokenisert tekst, finner ut navngitte enheter og markere disse\n",
    "        med XML tags. \"\"\"\n",
    "        sentences, _ = oblig1b_utils.preprocess(text)\n",
    "        spans = []\n",
    "        for sentence in sentences:\n",
    "            sentence = [token if token in self.vocab else \"<UNK>\" for token in sentence]\n",
    "            label_sequence, _ = self._beam_search(sentence)\n",
    "            spans.append(oblig1b_utils.get_spans(label_sequence))\n",
    "        \n",
    "        return oblig1b_utils.postprocess(sentences, spans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO-markering\n",
    "\n",
    "\n",
    "For å trene en HMM må hvert ord kobles til en merkelapp (_label_). En vanlig måte å gjøre dette er å bruke en såkalt BIO-markering, hvor hvert ord markeres som:\n",
    "* 'O' (hvis ordet ikke tilhører en navngitt entitet)\n",
    "* 'B-X' (hvis ordet er det første ordet i en navngitt entitet av type 'X')\n",
    "* 'I-X' (hvis ordet tilhører en entitet av type 'X', men ikke er det første ordet)\n",
    "\n",
    "__Oppgave 2.1__: Implementer funksjonen _get_BIO_sequence_ som tar som input en liste med ``text spans'' og setningslengden og gir tilbake en rekke (av samme lengde som setningen) med BIO-markeringer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_BIO_sequence(spans, sentence_length):\n",
    "    \"\"\"Gitt en liste over \"spans\", representert som tuples (start, end, tag),\n",
    "    og en setningslengde, produserer en sekvens med BIO (også kalt IOB) labeller\n",
    "    for setningen. \n",
    "    Eksempel: hvis spans=[(1,3,'ORG')] og sentence_length=6 bør resultatet være\n",
    "    ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']\"\"\"\n",
    "    \n",
    "    # Implementer metoden her!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Telling\n",
    "\n",
    "Som vi så i forelesningen er Hidden Markov Models definert med en vokabular (som tilsvarer ``observasjonene''), et sett mulig merkelapp (de skjulte tilstandene), og to sannsynlighetsfordelinger:\n",
    "* Den første fordelingen er kalt transisjonsmodell og definert som $P(label_t | label_{t-1})$. Transisjonsmodellen forteller oss hvor sannsynlig det er at $label_{t-1}$ (assosiert med ord $w_{t-1}$) følges av $label_t$ (assosiert med ord $w_t$). \n",
    "* Den andre fordelingen er emisjonsmodellen, definert som $P(w_t | label_t)$. Emisjonsmodellen forteller oss hvor sannsynlig det er å observere ordet $w_t$ hvis merkelappen for dette ordet er $label_t$.\n",
    "\n",
    "For å estimere disse to sannsynlighetsfordelinger må vi telle:\n",
    "* Alle ordene som forekommer i treningssettet\n",
    "* Alle BIO-labels som forekommer i treningssettet\n",
    "* Antall ganger hver BIO-label forekommer i treningssettet\n",
    "* Antall ganger to BIO-labels følger hverandre i treningssettet\n",
    "* Antall ganger et ord er observert med en BIO-label i treningssettet\n",
    "\n",
    "__Oppgave 2.2__: Implementer metoden `_add_counts` som oppdaterer variablene som inneholder disse tallene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "def _add_counts(self, sentence, label_sequence):\n",
    "    \"\"\"Oppdaterer variablene self.vocab, self.labels, self.label_counts, \n",
    "    self.transition_counts og  self.emission_counts, basert på setningen og \n",
    "    sekvenslabellene assosiert med dem. \n",
    "    Merk at setningen og label_sequence må ha samme lengde.\"\"\"\n",
    "        \n",
    "    # Implementer metoden her!\n",
    "    \n",
    "NamedEntityRecogniser._add_counts = _add_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sannsynligheterfordelinger\n",
    "\n",
    "Med hjelp av disse tallene kan vi nå estimere transisjonsmodellen og emisjonsmodellen. For emisjonsmodellen bør dere legge til _Laplace smoothing_ for å gjøre modellen mer robust, da treningssettet er relativt lite. La oss si at $C(label)$ er antall ganger BIO-merkelappen $label$ ble observert, og $C(label, token)$ antall ganger ordet $token$ ble observert sammen med $label$.  Ved hjelp av Laplace smoothing definerer vi sannsynligheten $P(token | label)$ slik:\n",
    "\n",
    "$$\n",
    "P(token | label) = \\frac{C(label, token) + \\alpha}{C(label) + \\alpha V}\n",
    "$$\n",
    "\n",
    "hvor $V$ er størrelsen på vokabularet. \n",
    "\n",
    "__Oppgave 2.3__: Implementer metoden `_fill_probs` som beregner transisjonsmodellen og emisjonsmodellen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_probs(self, alpha_smoothing=1E-6):\n",
    "    \"\"\"Beregne sannsynlihetsfordelinger self.transition_probs og\n",
    "    self.emission_probs basert på tallene som er samlet inn i \n",
    "    self.label_counts, self.transition_counts og self.emission_counts.\n",
    "        \n",
    "    Når det gjeler self.emission_probs bør vi legge Laplace smoothing, med en\n",
    "    verdi for alpha som er alpha_smoothing.\"\"\"\n",
    "        \n",
    "    # Implementer metoden her!\n",
    "    \n",
    "NamedEntityRecogniser._fill_probs = _fill_probs            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og vi kan nå trene modellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the model\n",
    "with open(\"norne_train.txt\") as fd:\n",
    "    model = NamedEntityRecogniser()\n",
    "    training_texts = fd.read()\n",
    "    model.fit(training_texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dekoding med beam search\n",
    "\n",
    "Til slutt skal vi implementere metoden `_beam_search` som skal finne den mest sannsynlige label-sekvensen for en setning ved hjelp av beam-search-algoritmen. \n",
    "\n",
    "Vi har sett hvordan beam search fungerer i forelesningen. Kort fortalt består et _beam_ av en mengde _hypoteser_, hvor en hypotese representerer her en mulig sekvens av BIO-labeller for setningen. Vi bygger opp disse hypotesene ord etter ord, inntil alle ordene er behandlet. I beam-search begrenser vi antall hypoteser som kan lagres etter hvert steg (=_beam width_) for å unngå en kombinatorisk eksplosjon.\n",
    "\n",
    "__Oppgave 2.4__: Implementer metoden `_beam_search`. For å gjøre det litt lettere er metoden allerede delvis implementert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _beam_search(self, sentence, beam_width=3):\n",
    "    \"\"\"Kjører beam search på setningen (liste over tokens), og\n",
    "    returnerer to outputs: \n",
    "    1) en labelsekvens (som har samme lengde som setningen)\n",
    "    2) sansynnlighet for hele sekvensen \"\"\"\n",
    "\n",
    "    # Vi starter med en beam som består av én tom hypotese\n",
    "    # Hver hypotese i beam består av to elementer:\n",
    "    # -'labels' er en liste over BIO-labels (en label per ord i setningen)\n",
    "    # -'prob' er sannsynligheten for denne labelsekvensen\n",
    "    beam = [{\"labels\":[], \"prob\":1.0}]\n",
    "\n",
    "    for token in sentence:\n",
    "        # Her må vi lage nye hypoteser som utvider de eksisterende\n",
    "        # hypotesene i beam med BIO-labeller for token\n",
    "        # (OBS: antall hypoteser i beam må ikke overstige beam_width)\n",
    "        raise NotImplementedError() \n",
    "        \n",
    "    # Vi velger hypotesen med høyest sannsynlighet\n",
    "    best_hypothesis = sorted(beam, key=lambda x : x[\"prob\"])[-1]\n",
    "\n",
    "    # Og returnerer labelsekvensen og dens sannsynlighet\n",
    "    return best_hypothesis[\"labels\"], best_hypothesis[\"prob\"]\n",
    "\n",
    "NamedEntityRecogniser._beam_search = _beam_search            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når dere har implementert modellen ferdig kan dere teste ut hvordan den fungerer ved å kalle metoden `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the model to a sample sentence\n",
    "model.label(\"Kjell Magne Bondevik var statsminister i Norge .\")\n",
    "# Forventet svar: '<PER>Kjell Magne Bondevik</PER> var statsminister i <GPE>Norge</GPE> .'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valgfritt spørsmål (for de modigste)\n",
    " \n",
    "Det er ofte en dårlig idé å gange mange små sannsynligheter, da vi kan havne i numerisk _underflow_. En vanlig løsning er å benytte log-sannsynligheter som kan summeres i stedet for å multipliseres, slik som forklart [her](http://www.cs.columbia.edu/~mcollins/cs4705-fall2018/notes-on-logs.pdf).\n",
    "\n",
    "__Oppgave 2.5__: Prøv å implementere beam search algoritmen med log-sannsynligheter.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3529d1d89cb4c8d13e402e4117b8dc865480f261d07f0716e8c60a591b54d3ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
